{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "94oYiPqBa6du"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.8.0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pathlib\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow_datasets as tfds\n",
        "from keras import regularizers\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_label_dir(df):\n",
        "    class_names = np.sort(df['label'].unique())\n",
        "    number_of_classes = len(class_names)\n",
        "\n",
        "    if not os.path.exists('../gdsc-ai-challenge/train'):\n",
        "        return class_names, number_of_classes\n",
        "\n",
        "    for class_name in class_names:\n",
        "        dir = pathlib.Path('../gdsc-ai-challenge/train/' + class_name)\n",
        "        if dir.exists():\n",
        "            continue\n",
        "        else:\n",
        "            dir.mkdir()\n",
        "    \n",
        "    return class_names, number_of_classes\n",
        "\n",
        "def sort_data(df):\n",
        "    if not os.path.exists('../gdsc-ai-challenge/train'):\n",
        "        return\n",
        "        \n",
        "    for image_dir in [str(img) for img in list(pathlib.Path('../gdsc-ai-challenge/train').glob('*.png'))]:\n",
        "        id = int(image_dir.removeprefix('../gdsc-ai-challenge/train/').removesuffix('.png'))\n",
        "        label = df['label'][id - 1]\n",
        "        dest_path = os.path.join('../gdsc-ai-challenge/train', label, str(id) + '.png')\n",
        "        shutil.move(image_dir, dest_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "label_df = pd.read_csv('../gdsc-ai-challenge/trainLabels.csv')\n",
        "\n",
        "class_names, number_of_classes = create_label_dir(label_df)\n",
        "sort_data(label_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0otttOT6bQIz",
        "outputId": "be1cb166-7ecd-4b6a-c6d3-ef1b66725683"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 35004 images belonging to 10 classes.\n",
            "Found 14996 images belonging to 10 classes.\n",
            "8.0\n",
            "(14996,)\n"
          ]
        }
      ],
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    validation_split=0.3,\n",
        "    rotation_range=15,\n",
        "    zoom_range=0.3,\n",
        "    horizontal_flip=True,\n",
        "    rescale=1.0/255,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "train_gen = datagen.flow_from_directory(\n",
        "    '../gdsc-ai-challenge/train',\n",
        "    target_size=(32,32),\n",
        "    batch_size=10,\n",
        "    subset='training',\n",
        "    seed=42,\n",
        "    color_mode='grayscale',\n",
        "    class_mode='sparse'\n",
        ")\n",
        "\n",
        "val_gen = datagen.flow_from_directory(\n",
        "    '../gdsc-ai-challenge/train',\n",
        "    target_size=(32,32),\n",
        "    batch_size=10,\n",
        "    subset='validation',\n",
        "    seed=42,\n",
        "    color_mode='grayscale',\n",
        "    class_mode='sparse'\n",
        ")\n",
        "\n",
        "print(val_gen[0][1][0])\n",
        "\n",
        "print(val_gen.classes.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "WNxHjoEeb8TB"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metal device set to: Apple M1\n",
            "\n",
            "systemMemory: 16.00 GB\n",
            "maxCacheSize: 5.33 GB\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-03-13 03:25:57.204553: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
            "2022-03-13 03:25:57.204663: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
          ]
        }
      ],
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Input((32,32,1)),\n",
        "    keras.layers.Conv2D(8, (5,5), padding='same',\n",
        "                        kernel_regularizer=regularizers.l2(1e-4),\n",
        "                        activity_regularizer=regularizers.l2(1e-4),\n",
        "                        kernel_initializer='he_normal',\n",
        "                        activation='elu'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Conv2D(8, (5,5), padding='same',\n",
        "                        kernel_regularizer=regularizers.l2(1e-4),\n",
        "                        activity_regularizer=regularizers.l2(1e-4),\n",
        "                        kernel_initializer='he_normal',\n",
        "                        activation='elu'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
        "    keras.layers.Conv2D(16, (3,3), padding='same',\n",
        "                        kernel_regularizer=regularizers.l2(1e-4),\n",
        "                        activity_regularizer=regularizers.l2(1e-4),\n",
        "                        kernel_initializer='he_normal',\n",
        "                        activation='elu'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Conv2D(16, (3,3), padding='same',\n",
        "                        kernel_regularizer=regularizers.l2(1e-4),\n",
        "                        activity_regularizer=regularizers.l2(1e-4),\n",
        "                        kernel_initializer='he_normal',\n",
        "                        activation='elu'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
        "    keras.layers.Conv2D(32, (3,3), padding='same',\n",
        "                        kernel_regularizer=regularizers.l2(1e-4),\n",
        "                        activity_regularizer=regularizers.l2(1e-4),\n",
        "                        kernel_initializer='he_normal',\n",
        "                        activation='elu'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Conv2D(32, (3,3), padding='same',\n",
        "                        kernel_regularizer=regularizers.l2(1e-4),\n",
        "                        activity_regularizer=regularizers.l2(1e-4),\n",
        "                        kernel_initializer='he_normal',\n",
        "                        activation='elu'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Conv2D(32, (3,3), padding='same',\n",
        "                        kernel_regularizer=regularizers.l2(1e-4),\n",
        "                        activity_regularizer=regularizers.l2(1e-4),\n",
        "                        kernel_initializer='he_normal',\n",
        "                        activation='elu'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
        "    keras.layers.Dropout(0.2),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(number_of_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
        "                                              loss='sparse_categorical_crossentropy',\n",
        "                                              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYXGttWEb89y",
        "outputId": "d5029a94-f07f-409d-d134-b0baa8cee9c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 32, 32, 8)         208       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 32, 32, 8)        32        \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 32, 32, 8)         1608      \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 32, 32, 8)        32        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 16, 16, 8)        0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 16, 16, 16)        1168      \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 16, 16, 16)       64        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 16, 16, 16)        2320      \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 16, 16, 16)       64        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 8, 8, 16)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 8, 8, 32)          4640      \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 8, 8, 32)         128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 8, 8, 32)          9248      \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 8, 8, 32)         128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 8, 8, 32)          9248      \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 8, 8, 32)         128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 4, 4, 32)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 4, 4, 32)          0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 34,146\n",
            "Trainable params: 33,858\n",
            "Non-trainable params: 288\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "6V5szfyncBDI"
      },
      "outputs": [],
      "source": [
        "class stopCallback(keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}) :\n",
        "        if (logs.get('val_accuracy') >= 0.999 and logs.get('accuracy') >= 0.999) :\n",
        "            print('\\nReached 99.9% accuracy so stopping training')\n",
        "            self.model.stop_training = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vTAeSb1cBwn",
        "outputId": "42b83134-f833-4e5b-ee2b-90803624b22f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-03-13 03:25:57.619035: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
            "2022-03-13 03:25:58.172077: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3499/3501 [============================>.] - ETA: 0s - loss: 3.8927 - accuracy: 0.2412"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-03-13 03:27:26.791189: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3501/3501 [==============================] - 103s 28ms/step - loss: 3.8925 - accuracy: 0.2412 - val_loss: 3.1648 - val_accuracy: 0.3130\n",
            "Epoch 2/1000\n",
            "3501/3501 [==============================] - 99s 28ms/step - loss: 3.0236 - accuracy: 0.3176 - val_loss: 2.8036 - val_accuracy: 0.3517\n",
            "Epoch 3/1000\n",
            "3501/3501 [==============================] - 100s 28ms/step - loss: 2.7304 - accuracy: 0.3568 - val_loss: 2.5936 - val_accuracy: 0.3810\n",
            "Epoch 4/1000\n",
            "3501/3501 [==============================] - 99s 28ms/step - loss: 2.5445 - accuracy: 0.3880 - val_loss: 2.4675 - val_accuracy: 0.3923\n",
            "Epoch 5/1000\n",
            "3501/3501 [==============================] - 102s 29ms/step - loss: 2.3943 - accuracy: 0.4084 - val_loss: 2.2868 - val_accuracy: 0.4360\n",
            "Epoch 6/1000\n",
            "3501/3501 [==============================] - 100s 28ms/step - loss: 2.2790 - accuracy: 0.4312 - val_loss: 2.2759 - val_accuracy: 0.4320\n",
            "Epoch 7/1000\n",
            "3501/3501 [==============================] - 99s 28ms/step - loss: 2.1862 - accuracy: 0.4463 - val_loss: 2.2219 - val_accuracy: 0.4285\n",
            "Epoch 8/1000\n",
            "3501/3501 [==============================] - 103s 29ms/step - loss: 2.1044 - accuracy: 0.4605 - val_loss: 2.0288 - val_accuracy: 0.4775\n",
            "Epoch 9/1000\n",
            "3501/3501 [==============================] - 101s 29ms/step - loss: 2.0362 - accuracy: 0.4721 - val_loss: 2.0091 - val_accuracy: 0.4841\n",
            "Epoch 10/1000\n",
            "3501/3501 [==============================] - 101s 29ms/step - loss: 1.9748 - accuracy: 0.4866 - val_loss: 1.9920 - val_accuracy: 0.4737\n",
            "Epoch 11/1000\n",
            "3501/3501 [==============================] - 103s 29ms/step - loss: 1.9136 - accuracy: 0.4964 - val_loss: 1.8582 - val_accuracy: 0.5169\n",
            "Epoch 12/1000\n",
            "3501/3501 [==============================] - 101s 29ms/step - loss: 1.8692 - accuracy: 0.5066 - val_loss: 1.8351 - val_accuracy: 0.5185\n",
            "Epoch 13/1000\n",
            "3501/3501 [==============================] - 104s 30ms/step - loss: 1.8197 - accuracy: 0.5141 - val_loss: 1.8114 - val_accuracy: 0.5129\n",
            "Epoch 14/1000\n",
            "3501/3501 [==============================] - 101s 29ms/step - loss: 1.7848 - accuracy: 0.5206 - val_loss: 1.7475 - val_accuracy: 0.5307\n",
            "Epoch 15/1000\n",
            "3501/3501 [==============================] - 99s 28ms/step - loss: 1.7521 - accuracy: 0.5295 - val_loss: 1.7107 - val_accuracy: 0.5441\n",
            "Epoch 16/1000\n",
            "3501/3501 [==============================] - 100s 28ms/step - loss: 1.7161 - accuracy: 0.5306 - val_loss: 1.7040 - val_accuracy: 0.5379\n",
            "Epoch 17/1000\n",
            "3501/3501 [==============================] - 101s 29ms/step - loss: 1.6774 - accuracy: 0.5392 - val_loss: 1.6737 - val_accuracy: 0.5396\n",
            "Epoch 18/1000\n",
            "3501/3501 [==============================] - 100s 29ms/step - loss: 1.6538 - accuracy: 0.5483 - val_loss: 1.6296 - val_accuracy: 0.5537\n",
            "Epoch 19/1000\n",
            "3501/3501 [==============================] - 107s 31ms/step - loss: 1.6230 - accuracy: 0.5505 - val_loss: 1.6155 - val_accuracy: 0.5555\n",
            "Epoch 20/1000\n",
            "3501/3501 [==============================] - 100s 28ms/step - loss: 1.6044 - accuracy: 0.5551 - val_loss: 1.5905 - val_accuracy: 0.5555\n",
            "Epoch 21/1000\n",
            "3501/3501 [==============================] - 101s 29ms/step - loss: 1.5765 - accuracy: 0.5609 - val_loss: 1.6400 - val_accuracy: 0.5429\n",
            "Epoch 22/1000\n",
            "3501/3501 [==============================] - 107s 31ms/step - loss: 1.5548 - accuracy: 0.5653 - val_loss: 1.5313 - val_accuracy: 0.5753\n",
            "Epoch 23/1000\n",
            "3501/3501 [==============================] - 100s 29ms/step - loss: 1.5296 - accuracy: 0.5694 - val_loss: 1.5092 - val_accuracy: 0.5744\n",
            "Epoch 24/1000\n",
            "3501/3501 [==============================] - 102s 29ms/step - loss: 1.5181 - accuracy: 0.5763 - val_loss: 1.5412 - val_accuracy: 0.5695\n",
            "Epoch 25/1000\n",
            "3501/3501 [==============================] - 108s 31ms/step - loss: 1.5001 - accuracy: 0.5767 - val_loss: 1.4551 - val_accuracy: 0.5964\n",
            "Epoch 26/1000\n",
            "3501/3501 [==============================] - 107s 31ms/step - loss: 1.4816 - accuracy: 0.5809 - val_loss: 1.5010 - val_accuracy: 0.5738\n",
            "Epoch 27/1000\n",
            "3501/3501 [==============================] - 100s 28ms/step - loss: 1.4652 - accuracy: 0.5858 - val_loss: 1.4547 - val_accuracy: 0.5866\n",
            "Epoch 28/1000\n",
            "3501/3501 [==============================] - 100s 29ms/step - loss: 1.4550 - accuracy: 0.5843 - val_loss: 1.4717 - val_accuracy: 0.5860\n",
            "Epoch 29/1000\n",
            "3501/3501 [==============================] - 107s 31ms/step - loss: 1.4392 - accuracy: 0.5897 - val_loss: 1.4497 - val_accuracy: 0.5887\n",
            "Epoch 30/1000\n",
            "3501/3501 [==============================] - 105s 30ms/step - loss: 1.4175 - accuracy: 0.5954 - val_loss: 1.4295 - val_accuracy: 0.5946\n",
            "Epoch 31/1000\n",
            "3501/3501 [==============================] - 99s 28ms/step - loss: 1.4170 - accuracy: 0.5913 - val_loss: 1.3807 - val_accuracy: 0.6098\n",
            "Epoch 32/1000\n",
            "3501/3501 [==============================] - 103s 29ms/step - loss: 1.4003 - accuracy: 0.5965 - val_loss: 1.4234 - val_accuracy: 0.5860\n",
            "Epoch 33/1000\n",
            "3501/3501 [==============================] - 100s 29ms/step - loss: 1.3916 - accuracy: 0.5988 - val_loss: 1.3965 - val_accuracy: 0.6052\n",
            "Epoch 34/1000\n",
            "3501/3501 [==============================] - 105s 30ms/step - loss: 1.3783 - accuracy: 0.5974 - val_loss: 1.3719 - val_accuracy: 0.6069\n",
            "Epoch 35/1000\n",
            "3501/3501 [==============================] - 99s 28ms/step - loss: 1.3725 - accuracy: 0.6020 - val_loss: 1.3704 - val_accuracy: 0.6098\n",
            "Epoch 36/1000\n",
            "3501/3501 [==============================] - 99s 28ms/step - loss: 1.3653 - accuracy: 0.6071 - val_loss: 1.3502 - val_accuracy: 0.6121\n",
            "Epoch 37/1000\n",
            "3501/3501 [==============================] - 104s 30ms/step - loss: 1.3428 - accuracy: 0.6116 - val_loss: 1.3993 - val_accuracy: 0.5984\n",
            "Epoch 38/1000\n",
            "3501/3501 [==============================] - 92s 26ms/step - loss: 1.3405 - accuracy: 0.6101 - val_loss: 1.3259 - val_accuracy: 0.6192\n",
            "Epoch 39/1000\n",
            "3501/3501 [==============================] - 103s 29ms/step - loss: 1.3314 - accuracy: 0.6121 - val_loss: 1.3324 - val_accuracy: 0.6116\n",
            "Epoch 40/1000\n",
            "3501/3501 [==============================] - 103s 29ms/step - loss: 1.3256 - accuracy: 0.6144 - val_loss: 1.3162 - val_accuracy: 0.6198\n",
            "Epoch 41/1000\n",
            "3501/3501 [==============================] - 103s 29ms/step - loss: 1.3176 - accuracy: 0.6172 - val_loss: 1.2907 - val_accuracy: 0.6325\n",
            "Epoch 42/1000\n",
            "3501/3501 [==============================] - 99s 28ms/step - loss: 1.3104 - accuracy: 0.6152 - val_loss: 1.3145 - val_accuracy: 0.6160\n",
            "Epoch 43/1000\n",
            "3501/3501 [==============================] - 95s 27ms/step - loss: 1.3004 - accuracy: 0.6199 - val_loss: 1.2978 - val_accuracy: 0.6248\n",
            "Epoch 44/1000\n",
            "3501/3501 [==============================] - 95s 27ms/step - loss: 1.2985 - accuracy: 0.6199 - val_loss: 1.3551 - val_accuracy: 0.6026\n",
            "Epoch 45/1000\n",
            "3501/3501 [==============================] - 97s 28ms/step - loss: 1.2909 - accuracy: 0.6210 - val_loss: 1.2716 - val_accuracy: 0.6296\n",
            "Epoch 46/1000\n",
            "3501/3501 [==============================] - 102s 29ms/step - loss: 1.2877 - accuracy: 0.6224 - val_loss: 1.3026 - val_accuracy: 0.6144\n",
            "Epoch 47/1000\n",
            "3501/3501 [==============================] - 93s 27ms/step - loss: 1.2819 - accuracy: 0.6233 - val_loss: 1.2590 - val_accuracy: 0.6355\n",
            "Epoch 48/1000\n",
            "3501/3501 [==============================] - 102s 29ms/step - loss: 1.2747 - accuracy: 0.6231 - val_loss: 1.2617 - val_accuracy: 0.6333\n",
            "Epoch 49/1000\n",
            "3501/3501 [==============================] - 103s 29ms/step - loss: 1.2667 - accuracy: 0.6263 - val_loss: 1.2810 - val_accuracy: 0.6274\n",
            "Epoch 50/1000\n",
            "3501/3501 [==============================] - 104s 30ms/step - loss: 1.2570 - accuracy: 0.6295 - val_loss: 1.2628 - val_accuracy: 0.6285\n",
            "Epoch 51/1000\n",
            "3501/3501 [==============================] - 99s 28ms/step - loss: 1.2566 - accuracy: 0.6297 - val_loss: 1.2308 - val_accuracy: 0.6403\n",
            "Epoch 52/1000\n",
            "3501/3501 [==============================] - 93s 27ms/step - loss: 1.2546 - accuracy: 0.6318 - val_loss: 1.2510 - val_accuracy: 0.6346\n",
            "Epoch 53/1000\n",
            "3501/3501 [==============================] - 92s 26ms/step - loss: 1.2430 - accuracy: 0.6320 - val_loss: 1.2548 - val_accuracy: 0.6305\n",
            "Epoch 54/1000\n",
            "3501/3501 [==============================] - 102s 29ms/step - loss: 1.2377 - accuracy: 0.6344 - val_loss: 1.2535 - val_accuracy: 0.6311\n",
            "Epoch 55/1000\n",
            "3501/3501 [==============================] - 103s 29ms/step - loss: 1.2391 - accuracy: 0.6332 - val_loss: 1.2340 - val_accuracy: 0.6426\n",
            "Epoch 56/1000\n",
            "3501/3501 [==============================] - 104s 30ms/step - loss: 1.2342 - accuracy: 0.6354 - val_loss: 1.2268 - val_accuracy: 0.6396\n",
            "Epoch 57/1000\n",
            "3501/3501 [==============================] - 99s 28ms/step - loss: 1.2261 - accuracy: 0.6370 - val_loss: 1.2473 - val_accuracy: 0.6292\n",
            "Epoch 58/1000\n",
            "3501/3501 [==============================] - 95s 27ms/step - loss: 1.2264 - accuracy: 0.6363 - val_loss: 1.2251 - val_accuracy: 0.6375\n",
            "Epoch 59/1000\n",
            "3501/3501 [==============================] - 93s 27ms/step - loss: 1.2143 - accuracy: 0.6404 - val_loss: 1.2238 - val_accuracy: 0.6390\n",
            "Epoch 60/1000\n",
            "3501/3501 [==============================] - 101s 29ms/step - loss: 1.2155 - accuracy: 0.6398 - val_loss: 1.2299 - val_accuracy: 0.6388\n",
            "Epoch 61/1000\n",
            "3501/3501 [==============================] - 95s 27ms/step - loss: 1.2133 - accuracy: 0.6401 - val_loss: 1.2067 - val_accuracy: 0.6412\n",
            "Epoch 62/1000\n",
            "3501/3501 [==============================] - 94s 27ms/step - loss: 1.2074 - accuracy: 0.6459 - val_loss: 1.1893 - val_accuracy: 0.6516\n",
            "Epoch 63/1000\n",
            "3501/3501 [==============================] - 96s 27ms/step - loss: 1.2106 - accuracy: 0.6388 - val_loss: 1.2167 - val_accuracy: 0.6467\n",
            "Epoch 64/1000\n",
            "3501/3501 [==============================] - 96s 27ms/step - loss: 1.1969 - accuracy: 0.6424 - val_loss: 1.2094 - val_accuracy: 0.6394\n",
            "Epoch 65/1000\n",
            "3501/3501 [==============================] - 102s 29ms/step - loss: 1.1902 - accuracy: 0.6491 - val_loss: 1.2565 - val_accuracy: 0.6314\n",
            "Epoch 66/1000\n",
            "3501/3501 [==============================] - 104s 30ms/step - loss: 1.1890 - accuracy: 0.6472 - val_loss: 1.2244 - val_accuracy: 0.6396\n",
            "Epoch 67/1000\n",
            "3501/3501 [==============================] - 103s 30ms/step - loss: 1.1937 - accuracy: 0.6436 - val_loss: 1.2104 - val_accuracy: 0.6406\n",
            "Epoch 68/1000\n",
            "3501/3501 [==============================] - 95s 27ms/step - loss: 1.1880 - accuracy: 0.6458 - val_loss: 1.2110 - val_accuracy: 0.6376\n",
            "Epoch 69/1000\n",
            "3501/3501 [==============================] - 99s 28ms/step - loss: 1.1844 - accuracy: 0.6447 - val_loss: 1.2066 - val_accuracy: 0.6410\n",
            "Epoch 70/1000\n",
            "3501/3501 [==============================] - 103s 29ms/step - loss: 1.1874 - accuracy: 0.6480 - val_loss: 1.1852 - val_accuracy: 0.6484\n",
            "Epoch 71/1000\n",
            "3501/3501 [==============================] - 103s 29ms/step - loss: 1.1808 - accuracy: 0.6512 - val_loss: 1.2045 - val_accuracy: 0.6440\n",
            "Epoch 72/1000\n",
            "3501/3501 [==============================] - 93s 27ms/step - loss: 1.1745 - accuracy: 0.6510 - val_loss: 1.1771 - val_accuracy: 0.6511\n",
            "Epoch 73/1000\n",
            "3501/3501 [==============================] - 103s 29ms/step - loss: 1.1692 - accuracy: 0.6501 - val_loss: 1.2019 - val_accuracy: 0.6448\n",
            "Epoch 74/1000\n",
            "3501/3501 [==============================] - 103s 29ms/step - loss: 1.1703 - accuracy: 0.6496 - val_loss: 1.1901 - val_accuracy: 0.6446\n",
            "Epoch 75/1000\n",
            "3501/3501 [==============================] - 104s 30ms/step - loss: 1.1685 - accuracy: 0.6507 - val_loss: 1.2088 - val_accuracy: 0.6370\n",
            "Epoch 76/1000\n",
            "3501/3501 [==============================] - 98s 28ms/step - loss: 1.1680 - accuracy: 0.6506 - val_loss: 1.1838 - val_accuracy: 0.6494\n",
            "Epoch 77/1000\n",
            "3501/3501 [==============================] - 96s 27ms/step - loss: 1.1626 - accuracy: 0.6546 - val_loss: 1.1521 - val_accuracy: 0.6576\n",
            "Epoch 78/1000\n",
            "3501/3501 [==============================] - 102s 29ms/step - loss: 1.1568 - accuracy: 0.6534 - val_loss: 1.1683 - val_accuracy: 0.6504\n",
            "Epoch 79/1000\n",
            "3501/3501 [==============================] - 102s 29ms/step - loss: 1.1612 - accuracy: 0.6553 - val_loss: 1.1725 - val_accuracy: 0.6501\n",
            "Epoch 80/1000\n",
            "3501/3501 [==============================] - 93s 27ms/step - loss: 1.1556 - accuracy: 0.6507 - val_loss: 1.1480 - val_accuracy: 0.6627\n",
            "Epoch 81/1000\n",
            "3501/3501 [==============================] - 96s 27ms/step - loss: 1.1474 - accuracy: 0.6563 - val_loss: 1.2088 - val_accuracy: 0.6386\n",
            "Epoch 82/1000\n",
            "3501/3501 [==============================] - 97s 28ms/step - loss: 1.1451 - accuracy: 0.6552 - val_loss: 1.1431 - val_accuracy: 0.6633\n",
            "Epoch 83/1000\n",
            "3501/3501 [==============================] - 93s 27ms/step - loss: 1.1514 - accuracy: 0.6564 - val_loss: 1.1501 - val_accuracy: 0.6586\n",
            "Epoch 84/1000\n",
            "3501/3501 [==============================] - 103s 29ms/step - loss: 1.1442 - accuracy: 0.6576 - val_loss: 1.1726 - val_accuracy: 0.6502\n",
            "Epoch 85/1000\n",
            "3501/3501 [==============================] - 103s 29ms/step - loss: 1.1414 - accuracy: 0.6578 - val_loss: 1.1805 - val_accuracy: 0.6441\n",
            "Epoch 86/1000\n",
            "3501/3501 [==============================] - 103s 29ms/step - loss: 1.1396 - accuracy: 0.6628 - val_loss: 1.1608 - val_accuracy: 0.6522\n",
            "Epoch 87/1000\n",
            "3501/3501 [==============================] - 104s 30ms/step - loss: 1.1387 - accuracy: 0.6561 - val_loss: 1.1545 - val_accuracy: 0.6594\n",
            "Epoch 88/1000\n",
            "3501/3501 [==============================] - 101s 29ms/step - loss: 1.1375 - accuracy: 0.6577 - val_loss: 1.1755 - val_accuracy: 0.6482\n",
            "Epoch 89/1000\n",
            "3501/3501 [==============================] - 95s 27ms/step - loss: 1.1327 - accuracy: 0.6578 - val_loss: 1.1862 - val_accuracy: 0.6396\n",
            "Epoch 90/1000\n",
            "3501/3501 [==============================] - 95s 27ms/step - loss: 1.1279 - accuracy: 0.6617 - val_loss: 1.1431 - val_accuracy: 0.6569\n",
            "Epoch 91/1000\n",
            "3501/3501 [==============================] - 94s 27ms/step - loss: 1.1286 - accuracy: 0.6579 - val_loss: 1.1313 - val_accuracy: 0.6620\n",
            "Epoch 92/1000\n",
            "3501/3501 [==============================] - 94s 27ms/step - loss: 1.1264 - accuracy: 0.6616 - val_loss: 1.1270 - val_accuracy: 0.6649\n",
            "Epoch 93/1000\n",
            "3501/3501 [==============================] - 96s 27ms/step - loss: 1.1283 - accuracy: 0.6594 - val_loss: 1.1364 - val_accuracy: 0.6637\n",
            "Epoch 94/1000\n",
            "3501/3501 [==============================] - 103s 29ms/step - loss: 1.1235 - accuracy: 0.6615 - val_loss: 1.1948 - val_accuracy: 0.6418\n",
            "Epoch 95/1000\n",
            "3501/3501 [==============================] - 102s 29ms/step - loss: 1.1163 - accuracy: 0.6641 - val_loss: 1.1448 - val_accuracy: 0.6563\n",
            "Epoch 96/1000\n",
            "3501/3501 [==============================] - 99s 28ms/step - loss: 1.1175 - accuracy: 0.6627 - val_loss: 1.1303 - val_accuracy: 0.6580\n",
            "Epoch 97/1000\n",
            "3501/3501 [==============================] - 95s 27ms/step - loss: 1.1164 - accuracy: 0.6645 - val_loss: 1.1188 - val_accuracy: 0.6679\n",
            "Epoch 98/1000\n",
            "3501/3501 [==============================] - 98s 28ms/step - loss: 1.1157 - accuracy: 0.6643 - val_loss: 1.1253 - val_accuracy: 0.6651\n",
            "Epoch 99/1000\n",
            "3501/3501 [==============================] - 94s 27ms/step - loss: 1.1072 - accuracy: 0.6662 - val_loss: 1.1553 - val_accuracy: 0.6528\n",
            "Epoch 100/1000\n",
            "3501/3501 [==============================] - 94s 27ms/step - loss: 1.1140 - accuracy: 0.6648 - val_loss: 1.1059 - val_accuracy: 0.6666\n",
            "Epoch 101/1000\n",
            "3501/3501 [==============================] - 95s 27ms/step - loss: 1.1117 - accuracy: 0.6661 - val_loss: 1.1361 - val_accuracy: 0.6623\n",
            "Epoch 102/1000\n",
            "3501/3501 [==============================] - 93s 27ms/step - loss: 1.1094 - accuracy: 0.6681 - val_loss: 1.1219 - val_accuracy: 0.6676\n",
            "Epoch 103/1000\n",
            "3501/3501 [==============================] - 94s 27ms/step - loss: 1.1040 - accuracy: 0.6680 - val_loss: 1.1254 - val_accuracy: 0.6630\n",
            "Epoch 104/1000\n",
            "3501/3501 [==============================] - 98s 28ms/step - loss: 1.1084 - accuracy: 0.6675 - val_loss: 1.1359 - val_accuracy: 0.6622\n",
            "Epoch 105/1000\n",
            "3501/3501 [==============================] - 92s 26ms/step - loss: 1.0992 - accuracy: 0.6672 - val_loss: 1.1182 - val_accuracy: 0.6642\n",
            "Epoch 106/1000\n",
            "3501/3501 [==============================] - 98s 28ms/step - loss: 1.1031 - accuracy: 0.6686 - val_loss: 1.1397 - val_accuracy: 0.6581\n",
            "Epoch 107/1000\n",
            "3501/3501 [==============================] - 95s 27ms/step - loss: 1.1059 - accuracy: 0.6678 - val_loss: 1.1091 - val_accuracy: 0.6705\n",
            "Epoch 108/1000\n",
            "3501/3501 [==============================] - 96s 27ms/step - loss: 1.1032 - accuracy: 0.6679 - val_loss: 1.1168 - val_accuracy: 0.6680\n",
            "Epoch 109/1000\n",
            "3501/3501 [==============================] - 98s 28ms/step - loss: 1.0950 - accuracy: 0.6720 - val_loss: 1.1104 - val_accuracy: 0.6688\n",
            "Epoch 110/1000\n",
            "3501/3501 [==============================] - 95s 27ms/step - loss: 1.0940 - accuracy: 0.6708 - val_loss: 1.1107 - val_accuracy: 0.6675\n",
            "Epoch 111/1000\n",
            "3501/3501 [==============================] - 101s 29ms/step - loss: 1.0932 - accuracy: 0.6682 - val_loss: 1.1503 - val_accuracy: 0.6508\n",
            "Epoch 112/1000\n",
            "3501/3501 [==============================] - 96s 27ms/step - loss: 1.0942 - accuracy: 0.6708 - val_loss: 1.1563 - val_accuracy: 0.6534\n",
            "Epoch 113/1000\n",
            "3501/3501 [==============================] - 95s 27ms/step - loss: 1.0900 - accuracy: 0.6702 - val_loss: 1.1010 - val_accuracy: 0.6701\n",
            "Epoch 114/1000\n",
            "3501/3501 [==============================] - 99s 28ms/step - loss: 1.0876 - accuracy: 0.6714 - val_loss: 1.1478 - val_accuracy: 0.6526\n",
            "Epoch 115/1000\n",
            "3501/3501 [==============================] - 95s 27ms/step - loss: 1.0883 - accuracy: 0.6690 - val_loss: 1.0962 - val_accuracy: 0.6682\n",
            "Epoch 116/1000\n",
            "3501/3501 [==============================] - 102s 29ms/step - loss: 1.0893 - accuracy: 0.6718 - val_loss: 1.1045 - val_accuracy: 0.6705\n",
            "Epoch 117/1000\n",
            "3501/3501 [==============================] - 95s 27ms/step - loss: 1.0799 - accuracy: 0.6728 - val_loss: 1.1124 - val_accuracy: 0.6678\n",
            "Epoch 118/1000\n",
            "3501/3501 [==============================] - 95s 27ms/step - loss: 1.0851 - accuracy: 0.6730 - val_loss: 1.0961 - val_accuracy: 0.6762\n",
            "Epoch 119/1000\n",
            "3501/3501 [==============================] - 94s 27ms/step - loss: 1.0767 - accuracy: 0.6781 - val_loss: 1.1178 - val_accuracy: 0.6643\n",
            "Epoch 120/1000\n",
            "3501/3501 [==============================] - 93s 26ms/step - loss: 1.0800 - accuracy: 0.6736 - val_loss: 1.0854 - val_accuracy: 0.6774\n",
            "Epoch 121/1000\n",
            "3501/3501 [==============================] - 97s 28ms/step - loss: 1.0810 - accuracy: 0.6725 - val_loss: 1.1048 - val_accuracy: 0.6691\n",
            "Epoch 122/1000\n",
            "3501/3501 [==============================] - 93s 27ms/step - loss: 1.0781 - accuracy: 0.6744 - val_loss: 1.1013 - val_accuracy: 0.6725\n",
            "Epoch 123/1000\n",
            "3501/3501 [==============================] - 93s 26ms/step - loss: 1.0743 - accuracy: 0.6753 - val_loss: 1.0907 - val_accuracy: 0.6749\n",
            "Epoch 124/1000\n",
            "3501/3501 [==============================] - 94s 27ms/step - loss: 1.0762 - accuracy: 0.6770 - val_loss: 1.0850 - val_accuracy: 0.6725\n",
            "Epoch 125/1000\n",
            "3501/3501 [==============================] - 94s 27ms/step - loss: 1.0756 - accuracy: 0.6744 - val_loss: 1.0984 - val_accuracy: 0.6720\n",
            "Epoch 126/1000\n",
            "3501/3501 [==============================] - 95s 27ms/step - loss: 1.0713 - accuracy: 0.6779 - val_loss: 1.0873 - val_accuracy: 0.6764\n",
            "Epoch 127/1000\n",
            "3501/3501 [==============================] - 100s 29ms/step - loss: 1.0761 - accuracy: 0.6781 - val_loss: 1.0944 - val_accuracy: 0.6700\n",
            "Epoch 128/1000\n",
            "3501/3501 [==============================] - 92s 26ms/step - loss: 1.0736 - accuracy: 0.6761 - val_loss: 1.0874 - val_accuracy: 0.6725\n",
            "Epoch 129/1000\n",
            "3501/3501 [==============================] - 100s 29ms/step - loss: 1.0707 - accuracy: 0.6790 - val_loss: 1.1141 - val_accuracy: 0.6660\n",
            "Epoch 130/1000\n",
            "3501/3501 [==============================] - 92s 26ms/step - loss: 1.0657 - accuracy: 0.6792 - val_loss: 1.1018 - val_accuracy: 0.6709\n",
            "Epoch 131/1000\n",
            "3501/3501 [==============================] - 93s 27ms/step - loss: 1.0731 - accuracy: 0.6747 - val_loss: 1.1135 - val_accuracy: 0.6632\n",
            "Epoch 132/1000\n",
            "3501/3501 [==============================] - 95s 27ms/step - loss: 1.0684 - accuracy: 0.6776 - val_loss: 1.0935 - val_accuracy: 0.6694\n",
            "Epoch 133/1000\n",
            "3501/3501 [==============================] - 95s 27ms/step - loss: 1.0703 - accuracy: 0.6777 - val_loss: 1.0791 - val_accuracy: 0.6755\n",
            "Epoch 134/1000\n",
            "3501/3501 [==============================] - 102s 29ms/step - loss: 1.0630 - accuracy: 0.6776 - val_loss: 1.1076 - val_accuracy: 0.6630\n",
            "Epoch 135/1000\n",
            "3501/3501 [==============================] - 100s 28ms/step - loss: 1.0656 - accuracy: 0.6765 - val_loss: 1.0844 - val_accuracy: 0.6732\n",
            "Epoch 136/1000\n",
            "3501/3501 [==============================] - 95s 27ms/step - loss: 1.0676 - accuracy: 0.6783 - val_loss: 1.0802 - val_accuracy: 0.6750\n",
            "Epoch 137/1000\n",
            "3501/3501 [==============================] - 96s 27ms/step - loss: 1.0606 - accuracy: 0.6776 - val_loss: 1.0815 - val_accuracy: 0.6746\n",
            "Epoch 138/1000\n",
            "3501/3501 [==============================] - 94s 27ms/step - loss: 1.0624 - accuracy: 0.6774 - val_loss: 1.0719 - val_accuracy: 0.6756\n",
            "Epoch 139/1000\n",
            "3501/3501 [==============================] - 95s 27ms/step - loss: 1.0613 - accuracy: 0.6789 - val_loss: 1.0902 - val_accuracy: 0.6702\n",
            "Epoch 140/1000\n",
            "3501/3501 [==============================] - 96s 27ms/step - loss: 1.0560 - accuracy: 0.6807 - val_loss: 1.0820 - val_accuracy: 0.6762\n",
            "Epoch 141/1000\n",
            "3501/3501 [==============================] - 93s 27ms/step - loss: 1.0561 - accuracy: 0.6786 - val_loss: 1.0910 - val_accuracy: 0.6689\n",
            "Epoch 142/1000\n",
            "3501/3501 [==============================] - 92s 26ms/step - loss: 1.0583 - accuracy: 0.6798 - val_loss: 1.0828 - val_accuracy: 0.6682\n",
            "Epoch 143/1000\n",
            "3501/3501 [==============================] - 93s 27ms/step - loss: 1.0500 - accuracy: 0.6810 - val_loss: 1.0747 - val_accuracy: 0.6801\n",
            "Epoch 144/1000\n",
            "3501/3501 [==============================] - 96s 27ms/step - loss: 1.0555 - accuracy: 0.6808 - val_loss: 1.0619 - val_accuracy: 0.6803\n",
            "Epoch 145/1000\n",
            "3501/3501 [==============================] - 97s 28ms/step - loss: 1.0525 - accuracy: 0.6822 - val_loss: 1.0835 - val_accuracy: 0.6744\n",
            "Epoch 146/1000\n",
            "3501/3501 [==============================] - 93s 27ms/step - loss: 1.0428 - accuracy: 0.6827 - val_loss: 1.0961 - val_accuracy: 0.6681\n",
            "Epoch 147/1000\n",
            "3501/3501 [==============================] - 94s 27ms/step - loss: 1.0522 - accuracy: 0.6825 - val_loss: 1.0931 - val_accuracy: 0.6688\n",
            "Epoch 148/1000\n",
            "3501/3501 [==============================] - 95s 27ms/step - loss: 1.0527 - accuracy: 0.6810 - val_loss: 1.0850 - val_accuracy: 0.6729\n",
            "Epoch 149/1000\n",
            "3501/3501 [==============================] - 92s 26ms/step - loss: 1.0496 - accuracy: 0.6850 - val_loss: 1.0760 - val_accuracy: 0.6776\n",
            "Epoch 150/1000\n",
            "3501/3501 [==============================] - 101s 29ms/step - loss: 1.0555 - accuracy: 0.6822 - val_loss: 1.0809 - val_accuracy: 0.6754\n",
            "Epoch 151/1000\n",
            "3501/3501 [==============================] - 95s 27ms/step - loss: 1.0491 - accuracy: 0.6849 - val_loss: 1.0632 - val_accuracy: 0.6766\n",
            "Epoch 152/1000\n",
            "3501/3501 [==============================] - 101s 29ms/step - loss: 1.0485 - accuracy: 0.6828 - val_loss: 1.0754 - val_accuracy: 0.6771\n",
            "Epoch 153/1000\n",
            "3501/3501 [==============================] - 99s 28ms/step - loss: 1.0429 - accuracy: 0.6844 - val_loss: 1.0746 - val_accuracy: 0.6758\n",
            "Epoch 154/1000\n",
            "3501/3501 [==============================] - 94s 27ms/step - loss: 1.0453 - accuracy: 0.6833 - val_loss: 1.0601 - val_accuracy: 0.6820\n",
            "Epoch 155/1000\n",
            "3501/3501 [==============================] - 93s 27ms/step - loss: 1.0467 - accuracy: 0.6825 - val_loss: 1.0636 - val_accuracy: 0.6793\n",
            "Epoch 156/1000\n",
            "3501/3501 [==============================] - 96s 27ms/step - loss: 1.0378 - accuracy: 0.6871 - val_loss: 1.0794 - val_accuracy: 0.6764\n",
            "Epoch 157/1000\n",
            "3501/3501 [==============================] - 94s 27ms/step - loss: 1.0398 - accuracy: 0.6835 - val_loss: 1.0580 - val_accuracy: 0.6756\n",
            "Epoch 158/1000\n",
            "3501/3501 [==============================] - 95s 27ms/step - loss: 1.0489 - accuracy: 0.6851 - val_loss: 1.0638 - val_accuracy: 0.6814\n",
            "Epoch 159/1000\n",
            "3501/3501 [==============================] - 93s 26ms/step - loss: 1.0404 - accuracy: 0.6856 - val_loss: 1.0641 - val_accuracy: 0.6812\n",
            "Epoch 160/1000\n",
            "3501/3501 [==============================] - 94s 27ms/step - loss: 1.0359 - accuracy: 0.6865 - val_loss: 1.0951 - val_accuracy: 0.6666\n",
            "Epoch 161/1000\n",
            "3501/3501 [==============================] - 94s 27ms/step - loss: 1.0331 - accuracy: 0.6864 - val_loss: 1.0640 - val_accuracy: 0.6810\n",
            "Epoch 162/1000\n",
            "3501/3501 [==============================] - 96s 27ms/step - loss: 1.0364 - accuracy: 0.6866 - val_loss: 1.0800 - val_accuracy: 0.6705\n",
            "Epoch 163/1000\n",
            "3501/3501 [==============================] - 94s 27ms/step - loss: 1.0336 - accuracy: 0.6865 - val_loss: 1.0732 - val_accuracy: 0.6787\n",
            "Epoch 164/1000\n",
            "3501/3501 [==============================] - 99s 28ms/step - loss: 1.0376 - accuracy: 0.6863 - val_loss: 1.0590 - val_accuracy: 0.6797\n",
            "Epoch 165/1000\n",
            "3501/3501 [==============================] - 95s 27ms/step - loss: 1.0383 - accuracy: 0.6876 - val_loss: 1.0677 - val_accuracy: 0.6731\n",
            "Epoch 166/1000\n",
            "3501/3501 [==============================] - 103s 29ms/step - loss: 1.0350 - accuracy: 0.6873 - val_loss: 1.0667 - val_accuracy: 0.6775\n",
            "Epoch 167/1000\n",
            "3501/3501 [==============================] - 97s 28ms/step - loss: 1.0369 - accuracy: 0.6872 - val_loss: 1.0584 - val_accuracy: 0.6804\n",
            "Epoch 168/1000\n",
            "3501/3501 [==============================] - 94s 27ms/step - loss: 1.0340 - accuracy: 0.6876 - val_loss: 1.0809 - val_accuracy: 0.6720\n",
            "Epoch 169/1000\n",
            "3501/3501 [==============================] - 95s 27ms/step - loss: 1.0304 - accuracy: 0.6874 - val_loss: 1.0539 - val_accuracy: 0.6848\n",
            "Epoch 170/1000\n",
            "3501/3501 [==============================] - 99s 28ms/step - loss: 1.0250 - accuracy: 0.6901 - val_loss: 1.0636 - val_accuracy: 0.6761\n",
            "Epoch 171/1000\n",
            "3501/3501 [==============================] - 95s 27ms/step - loss: 1.0316 - accuracy: 0.6892 - val_loss: 1.0756 - val_accuracy: 0.6720\n",
            "Epoch 172/1000\n",
            "3501/3501 [==============================] - 98s 28ms/step - loss: 1.0296 - accuracy: 0.6876 - val_loss: 1.0649 - val_accuracy: 0.6794\n",
            "Epoch 173/1000\n",
            "3501/3501 [==============================] - 94s 27ms/step - loss: 1.0322 - accuracy: 0.6887 - val_loss: 1.0600 - val_accuracy: 0.6832\n",
            "Epoch 174/1000\n",
            "3501/3501 [==============================] - 95s 27ms/step - loss: 1.0325 - accuracy: 0.6885 - val_loss: 1.0590 - val_accuracy: 0.6831\n",
            "Epoch 175/1000\n",
            "3501/3501 [==============================] - 94s 27ms/step - loss: 1.0291 - accuracy: 0.6878 - val_loss: 1.0712 - val_accuracy: 0.6742\n",
            "Epoch 176/1000\n",
            "3501/3501 [==============================] - 96s 28ms/step - loss: 1.0313 - accuracy: 0.6893 - val_loss: 1.0507 - val_accuracy: 0.6832\n",
            "Epoch 177/1000\n",
            "3501/3501 [==============================] - 96s 27ms/step - loss: 1.0301 - accuracy: 0.6891 - val_loss: 1.0516 - val_accuracy: 0.6881\n",
            "Epoch 178/1000\n",
            "3501/3501 [==============================] - 94s 27ms/step - loss: 1.0230 - accuracy: 0.6911 - val_loss: 1.0624 - val_accuracy: 0.6788\n",
            "Epoch 179/1000\n",
            "3501/3501 [==============================] - 94s 27ms/step - loss: 1.0210 - accuracy: 0.6907 - val_loss: 1.0737 - val_accuracy: 0.6704\n",
            "Epoch 180/1000\n",
            "3501/3501 [==============================] - 93s 27ms/step - loss: 1.0247 - accuracy: 0.6887 - val_loss: 1.0473 - val_accuracy: 0.6848\n",
            "Epoch 181/1000\n",
            "3501/3501 [==============================] - 95s 27ms/step - loss: 1.0291 - accuracy: 0.6872 - val_loss: 1.0678 - val_accuracy: 0.6783\n",
            "Epoch 182/1000\n",
            "3501/3501 [==============================] - 96s 27ms/step - loss: 1.0264 - accuracy: 0.6874 - val_loss: 1.0542 - val_accuracy: 0.6839\n",
            "Epoch 183/1000\n",
            "3501/3501 [==============================] - 96s 27ms/step - loss: 1.0205 - accuracy: 0.6930 - val_loss: 1.0497 - val_accuracy: 0.6864\n",
            "Epoch 184/1000\n",
            "3501/3501 [==============================] - 95s 27ms/step - loss: 1.0231 - accuracy: 0.6912 - val_loss: 1.0954 - val_accuracy: 0.6696\n",
            "Epoch 185/1000\n",
            "3501/3501 [==============================] - 95s 27ms/step - loss: 1.0183 - accuracy: 0.6909 - val_loss: 1.0717 - val_accuracy: 0.6726\n",
            "Epoch 186/1000\n",
            "3501/3501 [==============================] - 96s 28ms/step - loss: 1.0279 - accuracy: 0.6871 - val_loss: 1.0779 - val_accuracy: 0.6732\n",
            "Epoch 187/1000\n",
            "3501/3501 [==============================] - 94s 27ms/step - loss: 1.0175 - accuracy: 0.6934 - val_loss: 1.0494 - val_accuracy: 0.6832\n",
            "Epoch 188/1000\n",
            "3501/3501 [==============================] - 96s 27ms/step - loss: 1.0189 - accuracy: 0.6907 - val_loss: 1.0580 - val_accuracy: 0.6818\n",
            "Epoch 189/1000\n",
            "3501/3501 [==============================] - 95s 27ms/step - loss: 1.0198 - accuracy: 0.6888 - val_loss: 1.0482 - val_accuracy: 0.6822\n",
            "Epoch 190/1000\n",
            "3501/3501 [==============================] - 101s 29ms/step - loss: 1.0215 - accuracy: 0.6901 - val_loss: 1.0519 - val_accuracy: 0.6857\n",
            "Epoch 191/1000\n",
            "3501/3501 [==============================] - 97s 28ms/step - loss: 1.0257 - accuracy: 0.6886 - val_loss: 1.0665 - val_accuracy: 0.6772\n",
            "Epoch 192/1000\n",
            "3501/3501 [==============================] - 96s 27ms/step - loss: 1.0203 - accuracy: 0.6934 - val_loss: 1.0452 - val_accuracy: 0.6845\n",
            "Epoch 193/1000\n",
            "3501/3501 [==============================] - 93s 27ms/step - loss: 1.0166 - accuracy: 0.6923 - val_loss: 1.0727 - val_accuracy: 0.6791\n",
            "Epoch 194/1000\n",
            "3501/3501 [==============================] - 103s 29ms/step - loss: 1.0128 - accuracy: 0.6912 - val_loss: 1.0517 - val_accuracy: 0.6819\n",
            "Epoch 195/1000\n",
            "3501/3501 [==============================] - 100s 29ms/step - loss: 1.0155 - accuracy: 0.6915 - val_loss: 1.0706 - val_accuracy: 0.6736\n",
            "Epoch 196/1000\n",
            "3501/3501 [==============================] - 97s 28ms/step - loss: 1.0186 - accuracy: 0.6895 - val_loss: 1.0476 - val_accuracy: 0.6850\n",
            "Epoch 197/1000\n",
            "3501/3501 [==============================] - 93s 26ms/step - loss: 1.0218 - accuracy: 0.6895 - val_loss: 1.0493 - val_accuracy: 0.6828\n",
            "Epoch 198/1000\n",
            "3501/3501 [==============================] - 93s 27ms/step - loss: 1.0141 - accuracy: 0.6935 - val_loss: 1.0467 - val_accuracy: 0.6895\n",
            "Epoch 199/1000\n",
            "3501/3501 [==============================] - 93s 27ms/step - loss: 1.0175 - accuracy: 0.6911 - val_loss: 1.0556 - val_accuracy: 0.6811\n",
            "Epoch 200/1000\n",
            "3501/3501 [==============================] - 94s 27ms/step - loss: 1.0128 - accuracy: 0.6938 - val_loss: 1.0578 - val_accuracy: 0.6814\n",
            "Epoch 201/1000\n",
            "3501/3501 [==============================] - 95s 27ms/step - loss: 1.0153 - accuracy: 0.6921 - val_loss: 1.0451 - val_accuracy: 0.6832\n",
            "Epoch 202/1000\n",
            "3501/3501 [==============================] - 96s 28ms/step - loss: 1.0179 - accuracy: 0.6895 - val_loss: 1.0711 - val_accuracy: 0.6735\n",
            "Epoch 203/1000\n",
            "3501/3501 [==============================] - 97s 28ms/step - loss: 1.0118 - accuracy: 0.6949 - val_loss: 1.0561 - val_accuracy: 0.6732\n",
            "Epoch 204/1000\n",
            "3501/3501 [==============================] - 103s 29ms/step - loss: 1.0176 - accuracy: 0.6920 - val_loss: 1.0426 - val_accuracy: 0.6836\n",
            "Epoch 205/1000\n",
            "3501/3501 [==============================] - 94s 27ms/step - loss: 1.0090 - accuracy: 0.6928 - val_loss: 1.0475 - val_accuracy: 0.6838\n",
            "Epoch 206/1000\n",
            "3501/3501 [==============================] - 103s 29ms/step - loss: 1.0140 - accuracy: 0.6942 - val_loss: 1.0518 - val_accuracy: 0.6824\n",
            "Epoch 207/1000\n",
            "3501/3501 [==============================] - 98s 28ms/step - loss: 1.0107 - accuracy: 0.6925 - val_loss: 1.0320 - val_accuracy: 0.6892\n",
            "Epoch 208/1000\n",
            "3501/3501 [==============================] - 95s 27ms/step - loss: 1.0066 - accuracy: 0.6973 - val_loss: 1.0429 - val_accuracy: 0.6846\n",
            "Epoch 209/1000\n",
            "3501/3501 [==============================] - 94s 27ms/step - loss: 1.0135 - accuracy: 0.6903 - val_loss: 1.0357 - val_accuracy: 0.6860\n",
            "Epoch 210/1000\n",
            "3501/3501 [==============================] - 98s 28ms/step - loss: 1.0112 - accuracy: 0.6937 - val_loss: 1.0349 - val_accuracy: 0.6902\n",
            "Epoch 211/1000\n",
            "3501/3501 [==============================] - 93s 27ms/step - loss: 1.0129 - accuracy: 0.6905 - val_loss: 1.0465 - val_accuracy: 0.6832\n",
            "Epoch 212/1000\n",
            "3501/3501 [==============================] - 95s 27ms/step - loss: 1.0066 - accuracy: 0.6956 - val_loss: 1.0567 - val_accuracy: 0.6784\n",
            "Epoch 213/1000\n",
            "3501/3501 [==============================] - 94s 27ms/step - loss: 1.0031 - accuracy: 0.6951 - val_loss: 1.0494 - val_accuracy: 0.6792\n",
            "Epoch 214/1000\n",
            "3501/3501 [==============================] - 96s 27ms/step - loss: 1.0059 - accuracy: 0.6959 - val_loss: 1.0621 - val_accuracy: 0.6788\n",
            "Epoch 215/1000\n",
            "3501/3501 [==============================] - 93s 26ms/step - loss: 1.0066 - accuracy: 0.6952 - val_loss: 1.0328 - val_accuracy: 0.6931\n",
            "Epoch 216/1000\n",
            "3501/3501 [==============================] - 94s 27ms/step - loss: 0.9995 - accuracy: 0.6970 - val_loss: 1.0383 - val_accuracy: 0.6862\n",
            "Epoch 217/1000\n",
            "3501/3501 [==============================] - 94s 27ms/step - loss: 1.0071 - accuracy: 0.6950 - val_loss: 1.0505 - val_accuracy: 0.6771\n",
            "Epoch 218/1000\n",
            "3501/3501 [==============================] - 92s 26ms/step - loss: 1.0098 - accuracy: 0.6942 - val_loss: 1.0537 - val_accuracy: 0.6763\n",
            "Epoch 219/1000\n",
            "3501/3501 [==============================] - 95s 27ms/step - loss: 1.0034 - accuracy: 0.6933 - val_loss: 1.0326 - val_accuracy: 0.6901\n",
            "Epoch 220/1000\n",
            "3501/3501 [==============================] - 95s 27ms/step - loss: 1.0020 - accuracy: 0.6969 - val_loss: 1.0368 - val_accuracy: 0.6883\n",
            "Epoch 221/1000\n",
            "3501/3501 [==============================] - 94s 27ms/step - loss: 1.0089 - accuracy: 0.6938 - val_loss: 1.0614 - val_accuracy: 0.6700\n",
            "Epoch 222/1000\n",
            "3501/3501 [==============================] - 94s 27ms/step - loss: 1.0105 - accuracy: 0.6941 - val_loss: 1.0559 - val_accuracy: 0.6793\n",
            "Epoch 223/1000\n",
            "3501/3501 [==============================] - 95s 27ms/step - loss: 0.9979 - accuracy: 0.6993 - val_loss: 1.0426 - val_accuracy: 0.6840\n",
            "Epoch 224/1000\n",
            "3501/3501 [==============================] - 94s 27ms/step - loss: 1.0066 - accuracy: 0.6938 - val_loss: 1.0488 - val_accuracy: 0.6810\n",
            "Epoch 225/1000\n",
            "3501/3501 [==============================] - 95s 27ms/step - loss: 1.0020 - accuracy: 0.6969 - val_loss: 1.0407 - val_accuracy: 0.6827\n",
            "Epoch 226/1000\n",
            "3501/3501 [==============================] - 95s 27ms/step - loss: 1.0046 - accuracy: 0.6945 - val_loss: 1.0419 - val_accuracy: 0.6811\n",
            "Epoch 227/1000\n",
            "3501/3501 [==============================] - 94s 27ms/step - loss: 1.0055 - accuracy: 0.6939 - val_loss: 1.0362 - val_accuracy: 0.6876\n",
            "Epoch 228/1000\n",
            "3501/3501 [==============================] - 95s 27ms/step - loss: 1.0013 - accuracy: 0.6965 - val_loss: 1.0475 - val_accuracy: 0.6853\n",
            "Epoch 229/1000\n",
            "3501/3501 [==============================] - 95s 27ms/step - loss: 0.9993 - accuracy: 0.6982 - val_loss: 1.0554 - val_accuracy: 0.6824\n",
            "Epoch 230/1000\n",
            "3501/3501 [==============================] - 96s 27ms/step - loss: 1.0044 - accuracy: 0.6979 - val_loss: 1.0499 - val_accuracy: 0.6790\n",
            "Epoch 231/1000\n",
            "3501/3501 [==============================] - 93s 26ms/step - loss: 1.0003 - accuracy: 0.6975 - val_loss: 1.0322 - val_accuracy: 0.6901\n",
            "Epoch 232/1000\n",
            "3501/3501 [==============================] - 93s 27ms/step - loss: 1.0012 - accuracy: 0.6960 - val_loss: 1.0426 - val_accuracy: 0.6844\n",
            "Epoch 233/1000\n",
            "3501/3501 [==============================] - 96s 27ms/step - loss: 1.0016 - accuracy: 0.6957 - val_loss: 1.0459 - val_accuracy: 0.6858\n",
            "Epoch 234/1000\n",
            "3501/3501 [==============================] - 96s 28ms/step - loss: 0.9981 - accuracy: 0.6963 - val_loss: 1.0337 - val_accuracy: 0.6877\n",
            "Epoch 235/1000\n",
            "3501/3501 [==============================] - 93s 27ms/step - loss: 1.0018 - accuracy: 0.6973 - val_loss: 1.0367 - val_accuracy: 0.6858\n",
            "Epoch 236/1000\n",
            "3501/3501 [==============================] - 93s 27ms/step - loss: 1.0064 - accuracy: 0.6952 - val_loss: 1.0323 - val_accuracy: 0.6862\n",
            "Epoch 237/1000\n",
            "3501/3501 [==============================] - 93s 27ms/step - loss: 0.9986 - accuracy: 0.6978 - val_loss: 1.0837 - val_accuracy: 0.6712\n",
            "Epoch 238/1000\n",
            "3501/3501 [==============================] - 94s 27ms/step - loss: 0.9993 - accuracy: 0.6966 - val_loss: 1.0762 - val_accuracy: 0.6727\n",
            "Epoch 239/1000\n",
            "3501/3501 [==============================] - 94s 27ms/step - loss: 1.0032 - accuracy: 0.6959 - val_loss: 1.0422 - val_accuracy: 0.6875\n",
            "Epoch 240/1000\n",
            "3501/3501 [==============================] - 92s 26ms/step - loss: 0.9952 - accuracy: 0.6985 - val_loss: 1.0554 - val_accuracy: 0.6808\n",
            "Epoch 241/1000\n",
            "3501/3501 [==============================] - 94s 27ms/step - loss: 0.9985 - accuracy: 0.6987 - val_loss: 1.0618 - val_accuracy: 0.6750\n",
            "Epoch 242/1000\n",
            "3501/3501 [==============================] - 94s 27ms/step - loss: 0.9888 - accuracy: 0.7011 - val_loss: 1.0420 - val_accuracy: 0.6840\n",
            "Epoch 243/1000\n",
            "3501/3501 [==============================] - 93s 26ms/step - loss: 0.9954 - accuracy: 0.6965 - val_loss: 1.0546 - val_accuracy: 0.6788\n",
            "Epoch 244/1000\n",
            "3501/3501 [==============================] - 94s 27ms/step - loss: 0.9897 - accuracy: 0.6986 - val_loss: 1.0340 - val_accuracy: 0.6872\n",
            "Epoch 245/1000\n",
            "3501/3501 [==============================] - 97s 28ms/step - loss: 0.9908 - accuracy: 0.6988 - val_loss: 1.0400 - val_accuracy: 0.6842\n",
            "Epoch 246/1000\n",
            "3501/3501 [==============================] - 93s 27ms/step - loss: 0.9907 - accuracy: 0.6987 - val_loss: 1.0343 - val_accuracy: 0.6797\n",
            "Epoch 247/1000\n",
            "3501/3501 [==============================] - 93s 26ms/step - loss: 1.0008 - accuracy: 0.6965 - val_loss: 1.0262 - val_accuracy: 0.6923\n",
            "Epoch 248/1000\n",
            "3501/3501 [==============================] - 93s 27ms/step - loss: 0.9988 - accuracy: 0.6961 - val_loss: 1.0501 - val_accuracy: 0.6823\n",
            "Epoch 249/1000\n",
            "3501/3501 [==============================] - 94s 27ms/step - loss: 0.9934 - accuracy: 0.7005 - val_loss: 1.0450 - val_accuracy: 0.6837\n",
            "Epoch 250/1000\n",
            "3501/3501 [==============================] - 93s 27ms/step - loss: 0.9888 - accuracy: 0.7011 - val_loss: 1.0357 - val_accuracy: 0.6886\n",
            "Epoch 251/1000\n",
            "3501/3501 [==============================] - 93s 27ms/step - loss: 0.9908 - accuracy: 0.7010 - val_loss: 1.0350 - val_accuracy: 0.6852\n",
            "Epoch 252/1000\n",
            "3501/3501 [==============================] - 94s 27ms/step - loss: 0.9961 - accuracy: 0.7000 - val_loss: 1.0241 - val_accuracy: 0.6913\n",
            "Epoch 253/1000\n",
            "3501/3501 [==============================] - 94s 27ms/step - loss: 0.9924 - accuracy: 0.6971 - val_loss: 1.0372 - val_accuracy: 0.6849\n",
            "Epoch 254/1000\n",
            "3501/3501 [==============================] - 93s 27ms/step - loss: 0.9939 - accuracy: 0.6996 - val_loss: 1.0241 - val_accuracy: 0.6918\n",
            "Epoch 255/1000\n",
            "3501/3501 [==============================] - 94s 27ms/step - loss: 0.9889 - accuracy: 0.7024 - val_loss: 1.0329 - val_accuracy: 0.6889\n",
            "Epoch 256/1000\n",
            "3501/3501 [==============================] - 94s 27ms/step - loss: 0.9910 - accuracy: 0.6994 - val_loss: 1.1054 - val_accuracy: 0.6571\n",
            "Epoch 257/1000\n",
            "3501/3501 [==============================] - 94s 27ms/step - loss: 0.9877 - accuracy: 0.7005 - val_loss: 1.0435 - val_accuracy: 0.6856\n",
            "Epoch 258/1000\n",
            "3501/3501 [==============================] - 93s 26ms/step - loss: 0.9821 - accuracy: 0.7031 - val_loss: 1.0447 - val_accuracy: 0.6808\n",
            "Epoch 259/1000\n",
            "3501/3501 [==============================] - 93s 27ms/step - loss: 0.9917 - accuracy: 0.6990 - val_loss: 1.0533 - val_accuracy: 0.6828\n",
            "Epoch 260/1000\n",
            "3501/3501 [==============================] - 94s 27ms/step - loss: 0.9897 - accuracy: 0.7008 - val_loss: 1.0230 - val_accuracy: 0.6920\n",
            "Epoch 261/1000\n",
            "3501/3501 [==============================] - 94s 27ms/step - loss: 0.9875 - accuracy: 0.7014 - val_loss: 1.0387 - val_accuracy: 0.6876\n",
            "Epoch 262/1000\n",
            "3501/3501 [==============================] - 93s 27ms/step - loss: 0.9849 - accuracy: 0.7016 - val_loss: 1.0584 - val_accuracy: 0.6726\n",
            "Epoch 263/1000\n",
            "3501/3501 [==============================] - 93s 27ms/step - loss: 0.9888 - accuracy: 0.6992 - val_loss: 1.0350 - val_accuracy: 0.6876\n",
            "Epoch 264/1000\n",
            "3501/3501 [==============================] - 94s 27ms/step - loss: 0.9865 - accuracy: 0.7018 - val_loss: 1.0503 - val_accuracy: 0.6813\n",
            "Epoch 265/1000\n",
            "3501/3501 [==============================] - 94s 27ms/step - loss: 0.9803 - accuracy: 0.7042 - val_loss: 1.0498 - val_accuracy: 0.6824\n",
            "Epoch 266/1000\n",
            "3501/3501 [==============================] - 93s 27ms/step - loss: 0.9860 - accuracy: 0.6991 - val_loss: 1.0298 - val_accuracy: 0.6886\n",
            "Epoch 267/1000\n",
            "3501/3501 [==============================] - 93s 27ms/step - loss: 0.9886 - accuracy: 0.7019 - val_loss: 1.0357 - val_accuracy: 0.6879\n",
            "Epoch 268/1000\n",
            "3501/3501 [==============================] - 95s 27ms/step - loss: 0.9838 - accuracy: 0.7016 - val_loss: 1.0466 - val_accuracy: 0.6870\n",
            "Epoch 269/1000\n",
            "3501/3501 [==============================] - 93s 26ms/step - loss: 0.9850 - accuracy: 0.7017 - val_loss: 1.0297 - val_accuracy: 0.6911\n",
            "Epoch 270/1000\n",
            "3501/3501 [==============================] - 93s 27ms/step - loss: 0.9858 - accuracy: 0.7023 - val_loss: 1.0317 - val_accuracy: 0.6917\n",
            "Epoch 271/1000\n",
            "3501/3501 [==============================] - 94s 27ms/step - loss: 0.9848 - accuracy: 0.7013 - val_loss: 1.0262 - val_accuracy: 0.6899\n",
            "Epoch 272/1000\n",
            "3501/3501 [==============================] - 93s 27ms/step - loss: 0.9843 - accuracy: 0.7027 - val_loss: 1.0512 - val_accuracy: 0.6795\n",
            "Epoch 273/1000\n",
            "3501/3501 [==============================] - 93s 27ms/step - loss: 0.9911 - accuracy: 0.7014 - val_loss: 1.0360 - val_accuracy: 0.6876\n",
            "Epoch 274/1000\n",
            "3501/3501 [==============================] - 93s 27ms/step - loss: 0.9837 - accuracy: 0.7033 - val_loss: 1.0351 - val_accuracy: 0.6849\n",
            "Epoch 275/1000\n",
            "3501/3501 [==============================] - 93s 27ms/step - loss: 0.9811 - accuracy: 0.7050 - val_loss: 1.0311 - val_accuracy: 0.6892\n",
            "Epoch 276/1000\n",
            "3501/3501 [==============================] - 93s 27ms/step - loss: 0.9861 - accuracy: 0.7027 - val_loss: 1.0654 - val_accuracy: 0.6799\n",
            "Epoch 277/1000\n",
            "3501/3501 [==============================] - 93s 26ms/step - loss: 0.9817 - accuracy: 0.7058 - val_loss: 1.0292 - val_accuracy: 0.6937\n",
            "Epoch 278/1000\n",
            "3501/3501 [==============================] - 93s 27ms/step - loss: 0.9812 - accuracy: 0.7031 - val_loss: 1.0133 - val_accuracy: 0.6955\n",
            "Epoch 279/1000\n",
            "3501/3501 [==============================] - 94s 27ms/step - loss: 0.9858 - accuracy: 0.7038 - val_loss: 1.0289 - val_accuracy: 0.6883\n",
            "Epoch 280/1000\n",
            "3501/3501 [==============================] - 94s 27ms/step - loss: 0.9754 - accuracy: 0.7068 - val_loss: 1.0225 - val_accuracy: 0.6940\n",
            "Epoch 281/1000\n",
            "3501/3501 [==============================] - 93s 27ms/step - loss: 0.9867 - accuracy: 0.7008 - val_loss: 1.0414 - val_accuracy: 0.6891\n",
            "Epoch 282/1000\n",
            "3501/3501 [==============================] - 94s 27ms/step - loss: 0.9815 - accuracy: 0.7003 - val_loss: 1.0301 - val_accuracy: 0.6896\n",
            "Epoch 283/1000\n",
            "3501/3501 [==============================] - 93s 27ms/step - loss: 0.9825 - accuracy: 0.7045 - val_loss: 1.0334 - val_accuracy: 0.6899\n",
            "Epoch 284/1000\n",
            "3500/3501 [============================>.] - ETA: 0s - loss: 0.9781 - accuracy: 0.7041"
          ]
        }
      ],
      "source": [
        "callback = stopCallback()\n",
        "\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath='../Model/aiseries/version1.hdf5',\n",
        "                                                               monitor='val_loss',\n",
        "                                                               mode='min',\n",
        "                                                               save_best_only=True)\n",
        "\n",
        "history = model.fit(train_gen, \n",
        "                    epochs=1000, \n",
        "                    callbacks=[callback, model_checkpoint_callback], \n",
        "                    validation_data=val_gen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rwplY4tbcDpI"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'plt' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m/Users/danielnguyen/Repo/AI/Notebook/AI_Series.ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/danielnguyen/Repo/AI/Notebook/AI_Series.ipynb#ch0000008?line=0'>1</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(history\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m], color\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39morange\u001b[39m\u001b[39m'\u001b[39m, label\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTrain loss\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/danielnguyen/Repo/AI/Notebook/AI_Series.ipynb#ch0000008?line=1'>2</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(history\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m], color\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mblue\u001b[39m\u001b[39m'\u001b[39m, label\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mValidation loss\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/danielnguyen/Repo/AI/Notebook/AI_Series.ipynb#ch0000008?line=2'>3</a>\u001b[0m plt\u001b[39m.\u001b[39mlegend()\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ],
      "source": [
        "plt.plot(history.history['loss'], color='orange', label='Train loss')\n",
        "plt.plot(history.history['val_loss'], color='blue', label='Validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "AI Series.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
