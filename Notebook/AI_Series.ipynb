{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "94oYiPqBa6du"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pathlib\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow_datasets as tfds\n",
        "from keras import regularizers\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_label_dir(df):\n",
        "    class_names = np.sort(df['label'].unique())\n",
        "    number_of_classes = len(class_names)\n",
        "\n",
        "    if not os.path.exists('../gdsc-ai-challenge/train'):\n",
        "        return class_names, number_of_classes\n",
        "\n",
        "    for class_name in class_names:\n",
        "        dir = pathlib.Path('../gdsc-ai-challenge/train/' + class_name)\n",
        "        if dir.exists():\n",
        "            continue\n",
        "        else:\n",
        "            dir.mkdir()\n",
        "    \n",
        "    return class_names, number_of_classes\n",
        "\n",
        "def sort_data(df):\n",
        "    if not os.path.exists('../gdsc-ai-challenge/train'):\n",
        "        return\n",
        "        \n",
        "    for image_dir in [str(img) for img in list(pathlib.Path('../gdsc-ai-challenge/train/train').glob('*.png'))]:\n",
        "        id = int(image_dir.removeprefix('../gdsc-ai-challenge/train/train/').removesuffix('.png'))\n",
        "        label = df['label'][id - 1]\n",
        "        dest_path = os.path.join('../gdsc-ai-challenge/train', label, str(id) + '.png')\n",
        "        shutil.move(image_dir, dest_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "label_df = pd.read_csv('../gdsc-ai-challenge/trainLabels.csv')\n",
        "\n",
        "class_names, number_of_classes = create_label_dir(label_df)\n",
        "sort_data(label_df)\n",
        "os.rmdir('../gdsc-ai-challenge/train/train')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 50000 files belonging to 10 classes.\n",
            "3125\n"
          ]
        }
      ],
      "source": [
        "builder = tf.keras.utils.image_dataset_from_directory(\n",
        "    '../gdsc-ai-challenge/train',\n",
        "    color_mode='grayscale',\n",
        "    batch_size=16,\n",
        "    image_size=(32,32),\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "print(builder.cardinality().numpy())\n",
        "\n",
        "def get_dataset_partitions_tf(ds, ds_size, train_split=0.8, val_split=0.1, test_split=0.1, shuffle=True, shuffle_size=10000):\n",
        "    assert (train_split + test_split + val_split) == 1\n",
        "    \n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(shuffle_size, seed=42)\n",
        "    \n",
        "    train_size = int(train_split * ds_size)\n",
        "    val_size = int(val_split * ds_size)\n",
        "    \n",
        "    train_ds = ds.take(train_size)    \n",
        "    val_ds = ds.skip(train_size).take(val_size)\n",
        "    test_ds = ds.skip(train_size).skip(val_size)\n",
        "    \n",
        "    return train_ds, val_ds, test_ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0otttOT6bQIz",
        "outputId": "be1cb166-7ecd-4b6a-c6d3-ef1b66725683"
      },
      "outputs": [],
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    validation_split=0.3,\n",
        "    rotation_range=15,\n",
        "    zoom_range=0.3,\n",
        "    horizontal_flip=True,\n",
        "    rescale=1.0/255,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "train_gen = datagen.flow_from_directory(\n",
        "    '../gdsc-ai-challenge/train',\n",
        "    target_size=(32,32),\n",
        "    batch_size=10,\n",
        "    subset='training',\n",
        "    seed=42,\n",
        "    color_mode='grayscale',\n",
        "    class_mode='sparse'\n",
        ")\n",
        "\n",
        "val_gen = datagen.flow_from_directory(\n",
        "    '../gdsc-ai-challenge/train',\n",
        "    target_size=(32,32),\n",
        "    batch_size=10,\n",
        "    subset='validation',\n",
        "    seed=42,\n",
        "    color_mode='grayscale',\n",
        "    class_mode='sparse'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WNxHjoEeb8TB"
      },
      "outputs": [],
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Input((32,32,1)),\n",
        "    keras.layers.Conv2D(8, (5,5), padding='same',\n",
        "                        kernel_regularizer=regularizers.l2(1e-4),\n",
        "                        activity_regularizer=regularizers.l2(1e-4),\n",
        "                        kernel_initializer='he_normal',\n",
        "                        activation='elu'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Conv2D(8, (5,5), padding='same',\n",
        "                        kernel_regularizer=regularizers.l2(1e-4),\n",
        "                        activity_regularizer=regularizers.l2(1e-4),\n",
        "                        kernel_initializer='he_normal',\n",
        "                        activation='elu'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
        "    keras.layers.Conv2D(16, (3,3), padding='same',\n",
        "                        kernel_regularizer=regularizers.l2(1e-4),\n",
        "                        activity_regularizer=regularizers.l2(1e-4),\n",
        "                        kernel_initializer='he_normal',\n",
        "                        activation='elu'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Conv2D(16, (3,3), padding='same',\n",
        "                        kernel_regularizer=regularizers.l2(1e-4),\n",
        "                        activity_regularizer=regularizers.l2(1e-4),\n",
        "                        kernel_initializer='he_normal',\n",
        "                        activation='elu'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
        "    keras.layers.Conv2D(32, (3,3), padding='same',\n",
        "                        kernel_regularizer=regularizers.l2(1e-4),\n",
        "                        activity_regularizer=regularizers.l2(1e-4),\n",
        "                        kernel_initializer='he_normal',\n",
        "                        activation='elu'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Conv2D(32, (3,3), padding='same',\n",
        "                        kernel_regularizer=regularizers.l2(1e-4),\n",
        "                        activity_regularizer=regularizers.l2(1e-4),\n",
        "                        kernel_initializer='he_normal',\n",
        "                        activation='elu'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Conv2D(32, (3,3), padding='same',\n",
        "                        kernel_regularizer=regularizers.l2(1e-4),\n",
        "                        activity_regularizer=regularizers.l2(1e-4),\n",
        "                        kernel_initializer='he_normal',\n",
        "                        activation='elu'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
        "    keras.layers.Dropout(0.2),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(number_of_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
        "                                              loss='sparse_categorical_crossentropy',\n",
        "                                              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYXGttWEb89y",
        "outputId": "d5029a94-f07f-409d-d134-b0baa8cee9c3"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6V5szfyncBDI"
      },
      "outputs": [],
      "source": [
        "class stopCallback(keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}) :\n",
        "        if (logs.get('val_accuracy') >= 0.999 and logs.get('accuracy') >= 0.999) :\n",
        "            print('\\nReached 99.9% accuracy so stopping training')\n",
        "            self.model.stop_training = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vTAeSb1cBwn",
        "outputId": "42b83134-f833-4e5b-ee2b-90803624b22f"
      },
      "outputs": [],
      "source": [
        "callback = stopCallback()\n",
        "\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath='../Model/aiseries/version1.hdf5',\n",
        "                                                               monitor='val_loss',\n",
        "                                                               mode='min',\n",
        "                                                               save_best_only=True)\n",
        "\n",
        "history = model.fit(train_gen, \n",
        "                    epochs=1000, \n",
        "                    callbacks=[callback, model_checkpoint_callback], \n",
        "                    validation_data=val_gen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rwplY4tbcDpI"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['loss'], color='orange', label='Train loss')\n",
        "plt.plot(history.history['val_loss'], color='blue', label='Validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "AI Series.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
