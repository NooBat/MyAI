{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.core.magic import register_cell_magic\n",
        "\n",
        "@register_cell_magic\n",
        "def write_and_run(line, cell):\n",
        "    argz = line.split()\n",
        "    file = argz[-1]\n",
        "    mode = 'w'\n",
        "    if len(argz) == 2 and argz[0] == '-a':\n",
        "        mode = 'a'\n",
        "    with open(file, mode) as f:\n",
        "        f.write(cell)\n",
        "    get_ipython().run_cell(cell)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Import libraries and modules**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "94oYiPqBa6du"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import pathlib\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import regularizers\n",
        "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
        "import seaborn as sn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "sys.path.insert(0, '../')\n",
        "\n",
        "from generate_version import generate_version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Prepare the dataset for loading**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_label_dir(df, dir='../gdsc-ai-challenge/train'):\n",
        "    \"\"\"Use Dataframe contains labels for each image and path to the directory\n",
        "\n",
        "    contains the unlabeled dataset to rebuild directory into labeled subdirectories.\n",
        "\n",
        "    Returns all the label and number of classes in the dataset.\n",
        "\n",
        "    Keyword arguments:\n",
        "\n",
        "    df -- The Dataframe contains images' names and labels.\n",
        "\n",
        "    dir -- Path to the main directory (default to ../gdsc-ai-challenge/train)\n",
        "    \"\"\"\n",
        "    class_names = np.sort(df['label'].unique())\n",
        "    number_of_classes = len(class_names)\n",
        "\n",
        "    if not os.path.exists(dir):\n",
        "        return class_names, number_of_classes\n",
        "\n",
        "    for class_name in class_names:\n",
        "        subdir = pathlib.Path(os.path.join(dir, class_name))\n",
        "        if subdir.exists():\n",
        "            continue\n",
        "        else:\n",
        "            subdir.mkdir()\n",
        "    \n",
        "    return class_names, number_of_classes\n",
        "\n",
        "def sort_data(df, dir='../gdsc-ai-challenge/train'):\n",
        "    \"\"\"Use Dataframe to move each unlabeled image to the correct label's subdirectory.\n",
        "\n",
        "    df -- The Dataframe contains images' names and labels.\n",
        "\n",
        "    dir -- Path to the main directory (default to ../gdsc-ai-challenge/train) \n",
        "    \"\"\"\n",
        "    if not os.path.exists(dir):\n",
        "        return\n",
        "    \n",
        "    unlabeled_dir = os.path.join(dir, 'train')\n",
        "\n",
        "    for image_dir in [str(img) for img in list(pathlib.Path(unlabeled_dir).glob('*.png'))]:\n",
        "        id = int(image_dir.removeprefix(unlabeled_dir).removesuffix('.png'))\n",
        "        label = df['label'][id - 1]\n",
        "        dest_path = os.path.join(dir, label, str(id) + '.png')\n",
        "        shutil.move(image_dir, dest_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prepare the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "label_df = pd.read_csv('../gdsc-ai-challenge/trainLabels.csv')\n",
        "\n",
        "class_names, number_of_classes = create_label_dir(label_df)\n",
        "sort_data(label_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Data preprocessing and augmentation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def split_dataset(ds, ds_size, train_split=0.8, val_split=0.1, test_split=0.1):\n",
        "    \"\"\"Split the dataset into three subsets: train, validation (dev) and test set.\n",
        "\n",
        "    Returns three tuples, containing each subset with its size.\n",
        "\n",
        "    Keyword arguments:\n",
        "\n",
        "    ds -- tf.data.Dataset object\n",
        "\n",
        "    ds_size -- size of the dataset\n",
        "\n",
        "    train_split -- percentage to split into train set (default to 0.8)\n",
        "\n",
        "    val_split -- percentage to split into validation set (default to 0.1)\n",
        "\n",
        "    test_split -- percentage to split into test set (default to 0.1)\n",
        "    \"\"\"\n",
        "    assert (train_split + test_split + val_split) == 1\n",
        "    \n",
        "    train_size = int(train_split * ds_size)\n",
        "    val_size = int(val_split * ds_size)\n",
        "    \n",
        "    train_ds = ds.take(train_size)    \n",
        "    val_ds = ds.skip(train_size).take(val_size)\n",
        "    test_ds = ds.skip(train_size).skip(val_size)\n",
        "    \n",
        "    return (train_ds, train_size), (val_ds, val_size), (test_ds, ds_size - val_size - train_size)\n",
        "\n",
        "def configure(ds, ds_size, batch_size=32, shuffle=False, augment=False):\n",
        "    \"\"\"Configure the given dataset for better performance (by caching, prefetching and then batching the dataset)\n",
        "\n",
        "    and perform preprocessing to the images in the given dataset.\n",
        "\n",
        "    Returns the optimized dataset.\n",
        "\n",
        "    Keyword arguments:\n",
        "\n",
        "    ds -- tf.data.Dataset object\n",
        "\n",
        "    ds_size -- size of the dataset\n",
        "\n",
        "    batch_size -- size of each batch (default to 32)\n",
        "\n",
        "    shuffle -- whether to shuffle the dataset (default to False)\n",
        "\n",
        "    augment -- whether to perform data augmentation to the dataset (default to False)\n",
        "    \"\"\"\n",
        "\n",
        "    AUTOTUNE = tf.data.AUTOTUNE\n",
        "    rescale = keras.layers.Rescaling(1.0/255)\n",
        "    data_augmentation = keras.Sequential([\n",
        "        keras.layers.RandomFlip('horizontal'),\n",
        "        keras.layers.RandomRotation(0.05, fill_mode='nearest')\n",
        "    ])\n",
        "\n",
        "    ds = ds.map(lambda x, y: (rescale(x), y),\n",
        "                num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "    ds = ds.cache()\n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(buffer_size=int(ds_size * 0.6))\n",
        "    \n",
        "    ds = ds.batch(batch_size)\n",
        "\n",
        "    if augment:\n",
        "        with tf.device('/cpu:0'):\n",
        "            #only perform data augmentation on train set\n",
        "            ds = ds.map(lambda x, y: (data_augmentation(x, training=True), y),\n",
        "                                    num_parallel_calls=AUTOTUNE)\n",
        "    ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
        "    return ds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load the dataset using *image_dataset_from_directory()*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 50000 files belonging to 10 classes.\n",
            "Metal device set to: Apple M1\n",
            "\n",
            "systemMemory: 16.00 GB\n",
            "maxCacheSize: 5.33 GB\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-03-18 12:29:45.033662: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
            "2022-03-18 12:29:45.033814: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
          ]
        }
      ],
      "source": [
        "ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    '../gdsc-ai-challenge/train',\n",
        "    color_mode='grayscale',\n",
        "    batch_size=None,\n",
        "    image_size=(32,32),\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "ds_size = ds.cardinality().numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Split the dataset and Preprocess the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "(train_ds, train_size), (val_ds, val_size), (test_ds, test_size) = split_dataset(ds, ds_size, train_split=0.7, val_split=0.2, test_split=0.1)\n",
        "\n",
        "train_ds = configure(train_ds, train_size, augment=True, shuffle=True)\n",
        "val_ds = configure(val_ds, val_size)\n",
        "test_ds = configure(test_ds, test_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Create version-controlled folder for weights file**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "version = input(\"\"\"Create new folder?\n",
        "\n",
        "                (Y/n)    \n",
        "                \"\"\")\n",
        "\n",
        "new_version, path, weights_save_path = generate_version('../Model/aiseries', 'weights.best.hdf5', version.lower() == 'y')\n",
        "_, _, report_save_path = generate_version('../TrainingReport', new_version=version.lower() == 'y')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Build a model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "WNxHjoEeb8TB"
      },
      "outputs": [],
      "source": [
        "%%write_and_run {path}/model.py\n",
        "from tensorflow import keras\n",
        "from keras import regularizers\n",
        "import os\n",
        "\n",
        "def create_model(path_to_weights=None, load_weights=True):\n",
        "    \"\"\"Function to create a model\n",
        "\n",
        "    Returns a compiled and optionally loaded model\n",
        "\n",
        "    Keyword arguments:\n",
        "\n",
        "    path_to_weights -- (Optional, only used when load_weights is True) -- Path to weight file (.hdf5 files)\n",
        "\n",
        "    load_weights -- Whether to load weights or not (default to True)\n",
        "    \"\"\"\n",
        "    if (load_weights):\n",
        "        assert(path_to_weights is not None and \n",
        "           os.path.isfile(path_to_weights)), \"path_to_weights must exist and not be empty if load_weights is True, otherwise change load_weights to False\"\n",
        "\n",
        "    model = keras.models.Sequential([\n",
        "        keras.layers.Input((32,32,1)),\n",
        "        keras.layers.Conv2D(64, (3,3), padding='same',\n",
        "                            kernel_regularizer=regularizers.l2(1e-3),\n",
        "                            activity_regularizer=regularizers.l2(1e-4),\n",
        "                            kernel_initializer='he_normal',\n",
        "                            activation='elu'),\n",
        "        keras.layers.BatchNormalization(),\n",
        "        keras.layers.Conv2D(64, (3,3), padding='same',\n",
        "                            kernel_regularizer=regularizers.l2(1e-3),\n",
        "                            activity_regularizer=regularizers.l2(1e-4),\n",
        "                            kernel_initializer='he_normal',\n",
        "                            activation='elu'),\n",
        "        keras.layers.BatchNormalization(),\n",
        "        keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
        "\n",
        "        keras.layers.Conv2D(64, (3,3), padding='same',\n",
        "                            kernel_regularizer=regularizers.l2(1e-3),\n",
        "                            activity_regularizer=regularizers.l2(1e-4),\n",
        "                            kernel_initializer='he_normal',\n",
        "                            activation='elu'),\n",
        "        keras.layers.BatchNormalization(),\n",
        "        keras.layers.Conv2D(64, (3,3), padding='same',\n",
        "                            kernel_regularizer=regularizers.l2(1e-3),\n",
        "                            activity_regularizer=regularizers.l2(1e-4),\n",
        "                            kernel_initializer='he_normal',\n",
        "                            activation='elu'),\n",
        "        keras.layers.BatchNormalization(),\n",
        "        keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
        "\n",
        "        keras.layers.Conv2D(64, (3,3), padding='same',\n",
        "                            kernel_regularizer=regularizers.l2(1e-3),\n",
        "                            activity_regularizer=regularizers.l2(1e-4),\n",
        "                            kernel_initializer='he_normal',\n",
        "                            activation='elu'),\n",
        "        keras.layers.BatchNormalization(),\n",
        "        keras.layers.Conv2D(64, (3,3), padding='same',\n",
        "                            kernel_regularizer=regularizers.l2(1e-3),\n",
        "                            activity_regularizer=regularizers.l2(1e-4),\n",
        "                            kernel_initializer='he_normal',\n",
        "                            activation='elu'),\n",
        "        keras.layers.BatchNormalization(),\n",
        "        keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
        "\n",
        "        keras.layers.Conv2D(64, (1,1), padding='same',\n",
        "                            kernel_regularizer=regularizers.l2(1e-3),\n",
        "                            activity_regularizer=regularizers.l2(1e-4),\n",
        "                            kernel_initializer='he_normal',\n",
        "                            activation='elu'),\n",
        "        keras.layers.BatchNormalization(),\n",
        "        keras.layers.Conv2D(64, (1,1), padding='same',\n",
        "                            kernel_regularizer=regularizers.l2(1e-3),\n",
        "                            activity_regularizer=regularizers.l2(1e-4),\n",
        "                            kernel_initializer='he_normal',\n",
        "                            activation='elu'),\n",
        "        keras.layers.BatchNormalization(),\n",
        "        keras.layers.GlobalAveragePooling2D(),\n",
        "\n",
        "        keras.layers.Dropout(0.5),\n",
        "        keras.layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    if load_weights:\n",
        "        model.load_weights(path_to_weights)\n",
        "\n",
        "    model.compile(optimizer=keras.optimizers.Adam(),\n",
        "                                                loss='sparse_categorical_crossentropy',\n",
        "                                                metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYXGttWEb89y",
        "outputId": "d5029a94-f07f-409d-d134-b0baa8cee9c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 32, 32, 64)        640       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 32, 32, 64)       256       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 32, 32, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 32, 32, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 16, 16, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 16, 16, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 16, 16, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 16, 16, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 16, 16, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 8, 8, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 8, 8, 64)          36928     \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 8, 8, 64)         256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 8, 8, 64)          36928     \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 8, 8, 64)         256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 4, 4, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 4, 4, 64)          4160      \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 4, 4, 64)         256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 4, 4, 64)          4160      \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 4, 4, 64)         256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 64)               0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 196,298\n",
            "Trainable params: 195,274\n",
            "Non-trainable params: 1,024\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = create_model(load_weights=False)\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Training session**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Design a callback to stop training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "6V5szfyncBDI"
      },
      "outputs": [],
      "source": [
        "class stopCallback(keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}) :\n",
        "        if (logs.get('accuracy') >= 0.999 and logs.get('val_accuracy') >= 0.999) :\n",
        "            print('\\nReached 99.9% accuracy so stopping training')\n",
        "            self.model.stop_training = True\n",
        "\n",
        "callback = stopCallback()\n",
        "\n",
        "#callback to save weights with the minimum loss value\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=weights_save_path,\n",
        "                                                               monitor='val_loss',\n",
        "                                                               mode='min',\n",
        "                                                               save_best_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vTAeSb1cBwn",
        "outputId": "42b83134-f833-4e5b-ee2b-90803624b22f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-03-18 12:29:46.440716: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
            "2022-03-18 12:29:47.971076: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1094/1094 [==============================] - ETA: 0s - loss: 4.9821 - accuracy: 0.3309"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-03-18 12:31:43.491572: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1094/1094 [==============================] - 132s 117ms/step - loss: 4.9821 - accuracy: 0.3309 - val_loss: 3.5876 - val_accuracy: 0.3925\n",
            "Epoch 2/200\n",
            "1094/1094 [==============================] - 120s 110ms/step - loss: 2.9438 - accuracy: 0.4398 - val_loss: 2.6637 - val_accuracy: 0.4456\n",
            "Epoch 3/200\n",
            "1094/1094 [==============================] - 120s 109ms/step - loss: 2.2603 - accuracy: 0.5109 - val_loss: 2.4143 - val_accuracy: 0.4911\n",
            "Epoch 4/200\n",
            "1094/1094 [==============================] - 121s 111ms/step - loss: 1.9445 - accuracy: 0.5457 - val_loss: 2.7964 - val_accuracy: 0.3876\n",
            "Epoch 5/200\n",
            "1094/1094 [==============================] - 118s 108ms/step - loss: 1.7503 - accuracy: 0.5745 - val_loss: 1.9316 - val_accuracy: 0.5176\n",
            "Epoch 6/200\n",
            "1094/1094 [==============================] - 118s 108ms/step - loss: 1.6171 - accuracy: 0.5931 - val_loss: 2.2438 - val_accuracy: 0.4522\n",
            "Epoch 7/200\n",
            "1094/1094 [==============================] - 115s 105ms/step - loss: 1.4973 - accuracy: 0.6106 - val_loss: 1.5550 - val_accuracy: 0.5978\n",
            "Epoch 8/200\n",
            "1094/1094 [==============================] - 116s 106ms/step - loss: 1.4075 - accuracy: 0.6231 - val_loss: 1.7172 - val_accuracy: 0.5447\n",
            "Epoch 9/200\n",
            "1094/1094 [==============================] - 119s 109ms/step - loss: 1.3400 - accuracy: 0.6357 - val_loss: 1.8270 - val_accuracy: 0.5035\n",
            "Epoch 10/200\n",
            "1094/1094 [==============================] - 124s 114ms/step - loss: 1.3008 - accuracy: 0.6443 - val_loss: 1.4137 - val_accuracy: 0.6227\n",
            "Epoch 11/200\n",
            "1094/1094 [==============================] - 120s 109ms/step - loss: 1.2662 - accuracy: 0.6512 - val_loss: 2.1344 - val_accuracy: 0.4936\n",
            "Epoch 12/200\n",
            "1094/1094 [==============================] - 119s 108ms/step - loss: 1.2402 - accuracy: 0.6542 - val_loss: 1.4504 - val_accuracy: 0.6028\n",
            "Epoch 13/200\n",
            "1094/1094 [==============================] - 119s 109ms/step - loss: 1.2153 - accuracy: 0.6598 - val_loss: 2.1661 - val_accuracy: 0.4868\n",
            "Epoch 14/200\n",
            "1094/1094 [==============================] - 119s 109ms/step - loss: 1.2061 - accuracy: 0.6643 - val_loss: 1.3563 - val_accuracy: 0.6202\n",
            "Epoch 15/200\n",
            "1094/1094 [==============================] - 118s 108ms/step - loss: 1.1941 - accuracy: 0.6677 - val_loss: 1.7273 - val_accuracy: 0.5646\n",
            "Epoch 16/200\n",
            "1094/1094 [==============================] - 118s 108ms/step - loss: 1.1863 - accuracy: 0.6667 - val_loss: 1.6677 - val_accuracy: 0.5641\n",
            "Epoch 17/200\n",
            "1094/1094 [==============================] - 118s 108ms/step - loss: 1.1758 - accuracy: 0.6705 - val_loss: 1.7586 - val_accuracy: 0.5388\n",
            "Epoch 18/200\n",
            "1094/1094 [==============================] - 118s 108ms/step - loss: 1.1694 - accuracy: 0.6763 - val_loss: 1.3021 - val_accuracy: 0.6573\n",
            "Epoch 19/200\n",
            "1094/1094 [==============================] - 118s 108ms/step - loss: 1.1661 - accuracy: 0.6760 - val_loss: 2.0052 - val_accuracy: 0.5032\n",
            "Epoch 20/200\n",
            "1094/1094 [==============================] - 120s 110ms/step - loss: 1.1611 - accuracy: 0.6766 - val_loss: 1.4455 - val_accuracy: 0.6074\n",
            "Epoch 21/200\n",
            "1094/1094 [==============================] - 113s 103ms/step - loss: 1.1584 - accuracy: 0.6760 - val_loss: 1.2809 - val_accuracy: 0.6537\n",
            "Epoch 22/200\n",
            "1094/1094 [==============================] - 112s 102ms/step - loss: 1.1524 - accuracy: 0.6805 - val_loss: 3.5055 - val_accuracy: 0.3530\n",
            "Epoch 23/200\n",
            "1094/1094 [==============================] - 111s 102ms/step - loss: 1.1488 - accuracy: 0.6818 - val_loss: 1.4406 - val_accuracy: 0.6261\n",
            "Epoch 24/200\n",
            "1094/1094 [==============================] - 111s 101ms/step - loss: 1.1403 - accuracy: 0.6844 - val_loss: 1.4803 - val_accuracy: 0.6180\n",
            "Epoch 25/200\n",
            "1094/1094 [==============================] - 111s 101ms/step - loss: 1.1413 - accuracy: 0.6845 - val_loss: 2.0603 - val_accuracy: 0.5062\n",
            "Epoch 26/200\n",
            "1094/1094 [==============================] - 111s 102ms/step - loss: 1.1357 - accuracy: 0.6867 - val_loss: 1.2028 - val_accuracy: 0.6626\n",
            "Epoch 27/200\n",
            "1094/1094 [==============================] - 111s 101ms/step - loss: 1.1387 - accuracy: 0.6860 - val_loss: 1.2547 - val_accuracy: 0.6632\n",
            "Epoch 28/200\n",
            "1094/1094 [==============================] - 111s 102ms/step - loss: 1.1313 - accuracy: 0.6873 - val_loss: 1.5710 - val_accuracy: 0.5962\n",
            "Epoch 29/200\n",
            "1094/1094 [==============================] - 110s 101ms/step - loss: 1.1293 - accuracy: 0.6858 - val_loss: 1.8619 - val_accuracy: 0.5467\n",
            "Epoch 30/200\n",
            "1094/1094 [==============================] - 110s 101ms/step - loss: 1.1322 - accuracy: 0.6892 - val_loss: 1.3670 - val_accuracy: 0.6430\n",
            "Epoch 31/200\n",
            "1094/1094 [==============================] - 111s 102ms/step - loss: 1.1211 - accuracy: 0.6904 - val_loss: 1.4722 - val_accuracy: 0.6098\n",
            "Epoch 32/200\n",
            "1094/1094 [==============================] - 111s 101ms/step - loss: 1.1253 - accuracy: 0.6904 - val_loss: 2.8344 - val_accuracy: 0.3992\n",
            "Epoch 33/200\n",
            "1094/1094 [==============================] - 111s 101ms/step - loss: 1.1244 - accuracy: 0.6894 - val_loss: 1.3435 - val_accuracy: 0.6529\n",
            "Epoch 34/200\n",
            "1094/1094 [==============================] - 111s 101ms/step - loss: 1.1186 - accuracy: 0.6974 - val_loss: 3.2765 - val_accuracy: 0.3239\n",
            "Epoch 35/200\n",
            "1094/1094 [==============================] - 112s 102ms/step - loss: 1.1199 - accuracy: 0.6896 - val_loss: 1.7253 - val_accuracy: 0.5801\n",
            "Epoch 36/200\n",
            "1094/1094 [==============================] - 111s 101ms/step - loss: 1.1099 - accuracy: 0.6929 - val_loss: 1.7493 - val_accuracy: 0.5586\n",
            "Epoch 37/200\n",
            "1094/1094 [==============================] - 111s 101ms/step - loss: 1.1117 - accuracy: 0.6923 - val_loss: 1.2442 - val_accuracy: 0.6602\n",
            "Epoch 38/200\n",
            "1094/1094 [==============================] - 110s 101ms/step - loss: 1.1081 - accuracy: 0.6951 - val_loss: 1.3319 - val_accuracy: 0.6514\n",
            "Epoch 39/200\n",
            "1094/1094 [==============================] - 110s 101ms/step - loss: 1.1119 - accuracy: 0.6965 - val_loss: 1.2916 - val_accuracy: 0.6455\n",
            "Epoch 40/200\n",
            "1094/1094 [==============================] - 110s 101ms/step - loss: 1.0999 - accuracy: 0.6979 - val_loss: 1.8293 - val_accuracy: 0.5169\n",
            "Epoch 41/200\n",
            "1094/1094 [==============================] - 111s 101ms/step - loss: 1.1081 - accuracy: 0.6962 - val_loss: 1.5540 - val_accuracy: 0.6046\n",
            "Epoch 42/200\n",
            "1094/1094 [==============================] - 110s 101ms/step - loss: 1.1059 - accuracy: 0.6966 - val_loss: 1.6797 - val_accuracy: 0.5627\n",
            "Epoch 43/200\n",
            "1094/1094 [==============================] - 112s 103ms/step - loss: 1.1059 - accuracy: 0.6962 - val_loss: 1.2256 - val_accuracy: 0.6725\n",
            "Epoch 44/200\n",
            "1094/1094 [==============================] - 110s 101ms/step - loss: 1.1037 - accuracy: 0.6956 - val_loss: 1.7834 - val_accuracy: 0.5413\n",
            "Epoch 45/200\n",
            "1094/1094 [==============================] - 111s 101ms/step - loss: 1.1000 - accuracy: 0.6971 - val_loss: 1.9343 - val_accuracy: 0.5510\n",
            "Epoch 46/200\n",
            "1094/1094 [==============================] - 111s 102ms/step - loss: 1.0962 - accuracy: 0.6994 - val_loss: 1.2952 - val_accuracy: 0.6540\n",
            "Epoch 47/200\n",
            "1094/1094 [==============================] - 112s 102ms/step - loss: 1.1028 - accuracy: 0.6981 - val_loss: 1.2448 - val_accuracy: 0.6623\n",
            "Epoch 48/200\n",
            "1094/1094 [==============================] - 110s 101ms/step - loss: 1.1034 - accuracy: 0.6987 - val_loss: 1.3375 - val_accuracy: 0.6373\n",
            "Epoch 49/200\n",
            "1094/1094 [==============================] - 110s 101ms/step - loss: 1.0946 - accuracy: 0.6983 - val_loss: 1.2297 - val_accuracy: 0.6688\n",
            "Epoch 50/200\n",
            "1094/1094 [==============================] - 111s 101ms/step - loss: 1.0952 - accuracy: 0.7003 - val_loss: 1.9116 - val_accuracy: 0.5493\n",
            "Epoch 51/200\n",
            "1094/1094 [==============================] - 110s 100ms/step - loss: 1.0985 - accuracy: 0.6969 - val_loss: 2.5923 - val_accuracy: 0.4377\n",
            "Epoch 52/200\n",
            "1094/1094 [==============================] - ETA: 0s - loss: 1.0994 - accuracy: 0.7000"
          ]
        }
      ],
      "source": [
        "history = model.fit(train_ds, \n",
        "                    epochs=200, \n",
        "                    callbacks=[callback, model_checkpoint_callback], \n",
        "                    validation_data=val_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Model evaluation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluate on the test set using the best model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.load_weights(weights_save_path)\n",
        "\n",
        "model.evaluate(test_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluate based on training's metrics history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. Based on loss value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "number_of_epochs = len(history.history['loss'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rwplY4tbcDpI"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['loss'], color='red', label='Train loss')\n",
        "plt.plot(history.history['val_loss'], color='blue', label='Validation loss')\n",
        "\n",
        "plt.xticks(np.arange(number_of_epochs, step=4))\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Based on accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot(history.history['accuracy'], color='red', label='Training accuracy')\n",
        "plt.plot(history.history['val_accuracy'], color='blue', label='Validation accuracy')\n",
        "\n",
        "plt.xticks(np.arange(number_of_epochs, step=4))\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluate with Confusion Matrix and Classification Report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Generate actual and predicted value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_true = np.concatenate([y for _, y in test_ds], axis=0)\n",
        "\n",
        "Y_pred = model.predict(test_ds)\n",
        "y_pred = np.argmax(Y_pred, axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot Confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ConfusionMatrixDisplay.from_predictions(y_true, y_pred,\n",
        "                                        display_labels=[class_name.capitalize() for class_name in class_names],\n",
        "                                        cmap='Blues')\n",
        "plt.xticks(rotation=60)\n",
        "plt.savefig(os.path.join(report_save_path, 'confusion_matrix.pdf'))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot classification report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "clf_rep = classification_report(y_true, y_pred, \n",
        "                                target_names=[class_name.capitalize() for class_name in class_names], \n",
        "                                output_dict=True)\n",
        "\n",
        "sn.heatmap(pd.DataFrame(clf_rep).iloc[:-1,:].T, annot=True)\n",
        "plt.savefig(os.path.join(report_save_path, 'report.pdf'))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "AI Series.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
