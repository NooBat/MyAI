{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "94oYiPqBa6du"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pathlib\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow_datasets as tfds\n",
        "from keras import regularizers\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_label_dir(df):\n",
        "    class_names = np.sort(df['label'].unique())\n",
        "    number_of_classes = len(class_names)\n",
        "\n",
        "    if not os.path.exists('../gdsc-ai-challenge/train'):\n",
        "        return class_names, number_of_classes\n",
        "\n",
        "    for class_name in class_names:\n",
        "        dir = pathlib.Path('../gdsc-ai-challenge/train/' + class_name)\n",
        "        if dir.exists():\n",
        "            continue\n",
        "        else:\n",
        "            dir.mkdir()\n",
        "    \n",
        "    return class_names, number_of_classes\n",
        "\n",
        "def sort_data(df):\n",
        "    if not os.path.exists('../gdsc-ai-challenge/train'):\n",
        "        return\n",
        "        \n",
        "    for image_dir in [str(img) for img in list(pathlib.Path('../gdsc-ai-challenge/train/train').glob('*.png'))]:\n",
        "        id = int(image_dir.removeprefix('../gdsc-ai-challenge/train/train/').removesuffix('.png'))\n",
        "        label = df['label'][id - 1]\n",
        "        dest_path = os.path.join('../gdsc-ai-challenge/train', label, str(id) + '.png')\n",
        "        shutil.move(image_dir, dest_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "label_df = pd.read_csv('../gdsc-ai-challenge/trainLabels.csv')\n",
        "\n",
        "class_names, number_of_classes = create_label_dir(label_df)\n",
        "sort_data(label_df)\n",
        "os.rmdir('../gdsc-ai-challenge/train/train')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 0 files belonging to 10 classes.\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "No images found in directory ../gdsc-ai-challenge/train. Allowed formats: ('.bmp', '.gif', '.jpeg', '.jpg', '.png')",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m/Users/danielnguyen/Repo/AI/Notebook/AI_Series.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/danielnguyen/Repo/AI/Notebook/AI_Series.ipynb#ch0000010?line=0'>1</a>\u001b[0m builder \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mutils\u001b[39m.\u001b[39;49mimage_dataset_from_directory(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/danielnguyen/Repo/AI/Notebook/AI_Series.ipynb#ch0000010?line=1'>2</a>\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39m../gdsc-ai-challenge/train\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/danielnguyen/Repo/AI/Notebook/AI_Series.ipynb#ch0000010?line=2'>3</a>\u001b[0m     color_mode\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mgrayscale\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/danielnguyen/Repo/AI/Notebook/AI_Series.ipynb#ch0000010?line=3'>4</a>\u001b[0m     batch_size\u001b[39m=\u001b[39;49m\u001b[39m16\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/danielnguyen/Repo/AI/Notebook/AI_Series.ipynb#ch0000010?line=4'>5</a>\u001b[0m     image_size\u001b[39m=\u001b[39;49m(\u001b[39m32\u001b[39;49m,\u001b[39m32\u001b[39;49m),\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/danielnguyen/Repo/AI/Notebook/AI_Series.ipynb#ch0000010?line=5'>6</a>\u001b[0m     seed\u001b[39m=\u001b[39;49m\u001b[39m42\u001b[39;49m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/danielnguyen/Repo/AI/Notebook/AI_Series.ipynb#ch0000010?line=6'>7</a>\u001b[0m )\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/danielnguyen/Repo/AI/Notebook/AI_Series.ipynb#ch0000010?line=8'>9</a>\u001b[0m \u001b[39mprint\u001b[39m(builder\u001b[39m.\u001b[39minfo)\n",
            "File \u001b[0;32m~/miniforge3/envs/tk-ML/lib/python3.9/site-packages/keras/preprocessing/image_dataset.py:209\u001b[0m, in \u001b[0;36mimage_dataset_from_directory\u001b[0;34m(directory, labels, label_mode, class_names, color_mode, batch_size, image_size, shuffle, seed, validation_split, subset, interpolation, follow_links, crop_to_aspect_ratio, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/danielnguyen/miniforge3/envs/tk-ML/lib/python3.9/site-packages/keras/preprocessing/image_dataset.py?line=205'>206</a>\u001b[0m image_paths, labels \u001b[39m=\u001b[39m dataset_utils\u001b[39m.\u001b[39mget_training_or_validation_split(\n\u001b[1;32m    <a href='file:///Users/danielnguyen/miniforge3/envs/tk-ML/lib/python3.9/site-packages/keras/preprocessing/image_dataset.py?line=206'>207</a>\u001b[0m     image_paths, labels, validation_split, subset)\n\u001b[1;32m    <a href='file:///Users/danielnguyen/miniforge3/envs/tk-ML/lib/python3.9/site-packages/keras/preprocessing/image_dataset.py?line=207'>208</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m image_paths:\n\u001b[0;32m--> <a href='file:///Users/danielnguyen/miniforge3/envs/tk-ML/lib/python3.9/site-packages/keras/preprocessing/image_dataset.py?line=208'>209</a>\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mNo images found in directory \u001b[39m\u001b[39m{\u001b[39;00mdirectory\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    <a href='file:///Users/danielnguyen/miniforge3/envs/tk-ML/lib/python3.9/site-packages/keras/preprocessing/image_dataset.py?line=209'>210</a>\u001b[0m                    \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mAllowed formats: \u001b[39m\u001b[39m{\u001b[39;00mALLOWLIST_FORMATS\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m    <a href='file:///Users/danielnguyen/miniforge3/envs/tk-ML/lib/python3.9/site-packages/keras/preprocessing/image_dataset.py?line=211'>212</a>\u001b[0m dataset \u001b[39m=\u001b[39m paths_and_labels_to_dataset(\n\u001b[1;32m    <a href='file:///Users/danielnguyen/miniforge3/envs/tk-ML/lib/python3.9/site-packages/keras/preprocessing/image_dataset.py?line=212'>213</a>\u001b[0m     image_paths\u001b[39m=\u001b[39mimage_paths,\n\u001b[1;32m    <a href='file:///Users/danielnguyen/miniforge3/envs/tk-ML/lib/python3.9/site-packages/keras/preprocessing/image_dataset.py?line=213'>214</a>\u001b[0m     image_size\u001b[39m=\u001b[39mimage_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/danielnguyen/miniforge3/envs/tk-ML/lib/python3.9/site-packages/keras/preprocessing/image_dataset.py?line=218'>219</a>\u001b[0m     interpolation\u001b[39m=\u001b[39minterpolation,\n\u001b[1;32m    <a href='file:///Users/danielnguyen/miniforge3/envs/tk-ML/lib/python3.9/site-packages/keras/preprocessing/image_dataset.py?line=219'>220</a>\u001b[0m     crop_to_aspect_ratio\u001b[39m=\u001b[39mcrop_to_aspect_ratio)\n\u001b[1;32m    <a href='file:///Users/danielnguyen/miniforge3/envs/tk-ML/lib/python3.9/site-packages/keras/preprocessing/image_dataset.py?line=220'>221</a>\u001b[0m dataset \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mprefetch(tf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mAUTOTUNE)\n",
            "\u001b[0;31mValueError\u001b[0m: No images found in directory ../gdsc-ai-challenge/train. Allowed formats: ('.bmp', '.gif', '.jpeg', '.jpg', '.png')"
          ]
        }
      ],
      "source": [
        "builder = tf.keras.utils.image_dataset_from_directory(\n",
        "    '../gdsc-ai-challenge/train',\n",
        "    color_mode='grayscale',\n",
        "    batch_size=16,\n",
        "    image_size=(32,32),\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "print(builder.info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0otttOT6bQIz",
        "outputId": "be1cb166-7ecd-4b6a-c6d3-ef1b66725683"
      },
      "outputs": [],
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    validation_split=0.3,\n",
        "    rotation_range=15,\n",
        "    zoom_range=0.3,\n",
        "    horizontal_flip=True,\n",
        "    rescale=1.0/255,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "train_gen = datagen.flow_from_directory(\n",
        "    '../gdsc-ai-challenge/train',\n",
        "    target_size=(32,32),\n",
        "    batch_size=10,\n",
        "    subset='training',\n",
        "    seed=42,\n",
        "    color_mode='grayscale',\n",
        "    class_mode='sparse'\n",
        ")\n",
        "\n",
        "val_gen = datagen.flow_from_directory(\n",
        "    '../gdsc-ai-challenge/train',\n",
        "    target_size=(32,32),\n",
        "    batch_size=10,\n",
        "    subset='validation',\n",
        "    seed=42,\n",
        "    color_mode='grayscale',\n",
        "    class_mode='sparse'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WNxHjoEeb8TB"
      },
      "outputs": [],
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Input((32,32,1)),\n",
        "    keras.layers.Conv2D(8, (5,5), padding='same',\n",
        "                        kernel_regularizer=regularizers.l2(1e-4),\n",
        "                        activity_regularizer=regularizers.l2(1e-4),\n",
        "                        kernel_initializer='he_normal',\n",
        "                        activation='elu'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Conv2D(8, (5,5), padding='same',\n",
        "                        kernel_regularizer=regularizers.l2(1e-4),\n",
        "                        activity_regularizer=regularizers.l2(1e-4),\n",
        "                        kernel_initializer='he_normal',\n",
        "                        activation='elu'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
        "    keras.layers.Conv2D(16, (3,3), padding='same',\n",
        "                        kernel_regularizer=regularizers.l2(1e-4),\n",
        "                        activity_regularizer=regularizers.l2(1e-4),\n",
        "                        kernel_initializer='he_normal',\n",
        "                        activation='elu'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Conv2D(16, (3,3), padding='same',\n",
        "                        kernel_regularizer=regularizers.l2(1e-4),\n",
        "                        activity_regularizer=regularizers.l2(1e-4),\n",
        "                        kernel_initializer='he_normal',\n",
        "                        activation='elu'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
        "    keras.layers.Conv2D(32, (3,3), padding='same',\n",
        "                        kernel_regularizer=regularizers.l2(1e-4),\n",
        "                        activity_regularizer=regularizers.l2(1e-4),\n",
        "                        kernel_initializer='he_normal',\n",
        "                        activation='elu'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Conv2D(32, (3,3), padding='same',\n",
        "                        kernel_regularizer=regularizers.l2(1e-4),\n",
        "                        activity_regularizer=regularizers.l2(1e-4),\n",
        "                        kernel_initializer='he_normal',\n",
        "                        activation='elu'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Conv2D(32, (3,3), padding='same',\n",
        "                        kernel_regularizer=regularizers.l2(1e-4),\n",
        "                        activity_regularizer=regularizers.l2(1e-4),\n",
        "                        kernel_initializer='he_normal',\n",
        "                        activation='elu'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
        "    keras.layers.Dropout(0.2),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(number_of_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
        "                                              loss='sparse_categorical_crossentropy',\n",
        "                                              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYXGttWEb89y",
        "outputId": "d5029a94-f07f-409d-d134-b0baa8cee9c3"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6V5szfyncBDI"
      },
      "outputs": [],
      "source": [
        "class stopCallback(keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}) :\n",
        "        if (logs.get('val_accuracy') >= 0.999 and logs.get('accuracy') >= 0.999) :\n",
        "            print('\\nReached 99.9% accuracy so stopping training')\n",
        "            self.model.stop_training = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vTAeSb1cBwn",
        "outputId": "42b83134-f833-4e5b-ee2b-90803624b22f"
      },
      "outputs": [],
      "source": [
        "callback = stopCallback()\n",
        "\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath='../Model/aiseries/version1.hdf5',\n",
        "                                                               monitor='val_loss',\n",
        "                                                               mode='min',\n",
        "                                                               save_best_only=True)\n",
        "\n",
        "history = model.fit(train_gen, \n",
        "                    epochs=1000, \n",
        "                    callbacks=[callback, model_checkpoint_callback], \n",
        "                    validation_data=val_gen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rwplY4tbcDpI"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['loss'], color='orange', label='Train loss')\n",
        "plt.plot(history.history['val_loss'], color='blue', label='Validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "AI Series.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
