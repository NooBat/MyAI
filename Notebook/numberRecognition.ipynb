{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# directory = \"D:\\\\Code\\\\AI\\\\Model\\\\NumberRecognitionModel\"\n",
    "directory = \"/Users/danielnguyen/Repo/AI/Model/numberRecognitionModel\"\n",
    "\n",
    "new_version = input(\"Which version is this: \")\n",
    "versions_list = sorted([int(version.replace('version', '')) for version in os.listdir(directory) if version != \".DS_Store\"])\n",
    "\n",
    "try: \n",
    "    new_version = int(new_version)\n",
    "except:\n",
    "    latest_version = versions_list[-1]\n",
    "    new_version = latest_version + 1\n",
    "else:\n",
    "    new_version_folder = 'version{}'.format(int(new_version))\n",
    "    new_version_path = 'version{}.hdf5'.format(int(new_version))\n",
    "\n",
    "    path = os.path.join(directory, new_version_folder)\n",
    "    if versions_list.count(new_version) == 0:\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ImageDataGenerator(\n",
    "    rescale=1.0/255, \n",
    "    validation_split=0.2,\n",
    "    fill_mode='constant',\n",
    "    cval=0\n",
    ")\n",
    "\n",
    "train_ds = ds.flow_from_directory(\n",
    "    \"../numberLabel\", \n",
    "    target_size=(28,12), \n",
    "    batch_size=128,\n",
    "    subset='training',\n",
    "    color_mode='grayscale',\n",
    "    class_mode='sparse'\n",
    ")\n",
    "\n",
    "validation_ds = ds.flow_from_directory(\n",
    "    \"../numberLabel\", \n",
    "    target_size=(28,12), \n",
    "    batch_size=128,\n",
    "    subset='validation',\n",
    "    color_mode='grayscale',\n",
    "    class_mode='sparse'\n",
    ")\n",
    "\n",
    "input_shape = train_ds[0][0][0].shape\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (8,8)\n",
    "fig, axs = plt.subplots(4,4)\n",
    "\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        axs[i, j].imshow(validation_ds[0][0][i + j], cmap='gray')\n",
    "        axs[i, j].set_title(int(validation_ds[0][1][i + j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input((28,12,1)),\n",
    "    tf.keras.layers.Conv2D(8, (3,3), activation='elu',\n",
    "                        kernel_regularizer=tf.keras.regularizers.l2(1e-4), \n",
    "                        padding='same'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation='elu', \n",
    "                        kernel_regularizer=tf.keras.regularizers.l2(1e-4), \n",
    "                        padding='same'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='elu', \n",
    "                        kernel_regularizer=tf.keras.regularizers.l2(1e-4), \n",
    "                        padding='same'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(32, activation='elu', kernel_regularizer=tf.keras.regularizers.l2(1e-4)),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0003),\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=[tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                    'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile {path}/model.py\n",
    "import tensorflow as tf\n",
    "\n",
    "def create_model() :\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Input((28,12,1)),\n",
    "        tf.keras.layers.Conv2D(8, (3,3), activation='elu',\n",
    "                            kernel_regularizer=tf.keras.regularizers.l2(1e-4), \n",
    "                            padding='same'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "        tf.keras.layers.Conv2D(16, (3,3), activation='elu', \n",
    "                            kernel_regularizer=tf.keras.regularizers.l2(1e-4), \n",
    "                            padding='same'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "        tf.keras.layers.Conv2D(32, (3,3), activation='elu', \n",
    "                            kernel_regularizer=tf.keras.regularizers.l2(1e-4), \n",
    "                            padding='same'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(32, activation='elu', kernel_regularizer=tf.keras.regularizers.l2(1e-4)),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0003),\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=[tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                        'accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class stopCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}) :\n",
    "        if (logs.get('val_accuracy') >= 0.999 and logs.get('accuracy') >= 0.999) :\n",
    "            print('\\nReached 99% accuracy so stopping training')\n",
    "            self.model.stop_training = True\n",
    "\n",
    "\n",
    "\n",
    "save_path = os.path.join(path, new_version_path)\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=save_path,\n",
    "                                                               monitor='val_accuracy',\n",
    "                                                               mode='max',\n",
    "                                                               save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = stopCallback()\n",
    "\n",
    "history = model.fit(train_ds, \n",
    "                    epochs=200, \n",
    "                    callbacks=[callback, model_checkpoint_callback], \n",
    "                    validation_data=validation_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], color='orange', label='Train loss')\n",
    "plt.plot(history.history['val_loss'], color='blue', label='Validation loss')\n",
    "plt.ylim((0, 0.6))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], color='orange', label='Train accuracy')\n",
    "plt.plot(history.history['val_accuracy'], color='blue', label='Validation accuracy')\n",
    "plt.ylim((0.7, 1))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = validation_ds[1][0][100]\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "plt.imshow(test_img, cmap='gray')\n",
    "\n",
    "print(np.argmax(model.predict(np.expand_dims(test_img, 0))))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "03e0c0c2b06b1fd2dee4643aa150eec8def2c2441a2970a915ed1b11d6d57cb0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('gpuAI': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
